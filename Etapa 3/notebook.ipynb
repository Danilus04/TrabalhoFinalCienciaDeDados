{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "114adf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necess√°rias\n",
    "import pandas as pd\n",
    "import os\n",
    "import kagglehub\n",
    "import shutil\n",
    "import requests\n",
    "import gzip\n",
    "import duckdb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7bef250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/shivamb/amazon-prime-movies-and-tv-shows?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.61M/1.61M [00:00<00:00, 2.62MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/shivamb/disney-movies-and-tv-shows?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 131k/131k [00:00<00:00, 541kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/shivamb/netflix-shows?dataset_version_number=5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.34M/1.34M [00:00<00:00, 1.61MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "\n",
      "\n",
      "--- Processo Finalizado ---\n",
      "Todos os arquivos dos datasets est√£o na pasta: h:\\Estudos\\Codigos\\CienciaDeDados\\ReposotorioDoGit\\TrabalhoFinal\\Etapa 3\\data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DATASETS = [\n",
    "    \"shivamb/amazon-prime-movies-and-tv-shows\",\n",
    "    \"shivamb/disney-movies-and-tv-shows\",\n",
    "    \"shivamb/netflix-shows\",\n",
    "]\n",
    "\n",
    "current_directory = os.getcwd() \n",
    "DESTINATION_DIR = os.path.join(current_directory, \"data\") \n",
    "\n",
    "# 1. Cria a pasta 'data' se ela n√£o existir\n",
    "os.makedirs(DESTINATION_DIR, exist_ok=True)\n",
    "\n",
    "def download_and_copy_dataset(dataset_name: str, destination_path: str):\n",
    "    \"\"\"Baixa um dataset, copia os arquivos para o destino e limpa o cache.\"\"\"\n",
    "\n",
    "    # 1. Baixa o dataset para o cache\n",
    "    try:\n",
    "        cache_path = kagglehub.dataset_download(dataset_name)\n",
    "    except Exception as e:\n",
    "        return\n",
    "\n",
    "    # 2. Copia os arquivos do cache para o diret√≥rio de destino\n",
    "    for item_name in os.listdir(cache_path):\n",
    "        source = os.path.join(cache_path, item_name)\n",
    "        destination = os.path.join(destination_path, item_name)\n",
    "\n",
    "        # Copia apenas arquivos (ignorando subpastas)\n",
    "        if os.path.isfile(source):\n",
    "            shutil.copy2(source, destination) \n",
    "\n",
    "    # 3. Remove completamente a pasta do cache\n",
    "    try:\n",
    "        shutil.rmtree(cache_path)\n",
    "    except OSError as e:\n",
    "        print(f\"  > AVISO: N√£o foi poss√≠vel remover o cache: {e}\")\n",
    "        \n",
    "for dataset in DATASETS:\n",
    "    download_and_copy_dataset(dataset, DESTINATION_DIR)\n",
    "\n",
    "print(\"\\n\\n--- Processo Finalizado ---\")\n",
    "print(f\"Todos os arquivos dos datasets est√£o na pasta: {DESTINATION_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c71f7d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando downloads... (Isso pode levar v√°rios minutos por arquivo)\n",
      "\n",
      "Baixando: title.basics.tsv.gz...\n",
      "Download conclu√≠do.\n",
      "Descomprimindo: title.basics.tsv.gz...\n",
      "Arquivo salvo: data\\title.basics.tsv\n",
      "Arquivo tempor√°rio 'data\\title.basics.tsv.gz' removido.\n",
      "\n",
      "Baixando: title.ratings.tsv.gz...\n",
      "Download conclu√≠do.\n",
      "Descomprimindo: title.ratings.tsv.gz...\n",
      "Arquivo salvo: data\\title.ratings.tsv\n",
      "Arquivo tempor√°rio 'data\\title.ratings.tsv.gz' removido.\n",
      "\n",
      "Baixando: title.crew.tsv.gz...\n",
      "Download conclu√≠do.\n",
      "Descomprimindo: title.crew.tsv.gz...\n",
      "Arquivo salvo: data\\title.crew.tsv\n",
      "Arquivo tempor√°rio 'data\\title.crew.tsv.gz' removido.\n",
      "\n",
      "Baixando: name.basics.tsv.gz...\n",
      "Download conclu√≠do.\n",
      "Descomprimindo: name.basics.tsv.gz...\n",
      "Arquivo salvo: data\\name.basics.tsv\n",
      "Arquivo tempor√°rio 'data\\name.basics.tsv.gz' removido.\n",
      "\n",
      "Processo conclu√≠do! Os arquivos TSV est√£o em: 'data'\n"
     ]
    }
   ],
   "source": [
    "def baixar_e_descomprimir_imdb(output_dir=\"data\"):\n",
    "    \"\"\"\n",
    "    Baixa os arquivos de dataset do IMDb e os descomprime.\n",
    "    Os arquivos s√£o salvos no diret√≥rio 'output_dir'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # URL base dos datasets\n",
    "    base_url = \"https://datasets.imdbws.com/\"\n",
    "    \n",
    "    # Arquivos necess√°rios para (Nome da Obra, Nota, Diretor)\n",
    "    files_to_download = [\n",
    "        \"title.basics.tsv.gz\",   # Mapeia tconst -> primaryTitle (Nome da Obra)\n",
    "        \"title.ratings.tsv.gz\",  # Mapeia tconst -> averageRating (Nota)\n",
    "        \"title.crew.tsv.gz\",     # Mapeia tconst -> nconst (ID do Diretor)\n",
    "        \"name.basics.tsv.gz\"     # Mapeia nconst -> primaryName (Nome da Pessoa)\n",
    "    ]\n",
    "    \n",
    "    # Cria o diret√≥rio de sa√≠da se ele n√£o existir\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Diret√≥rio criado: '{output_dir}'\")\n",
    "\n",
    "    print(\"Iniciando downloads... (Isso pode levar v√°rios minutos por arquivo)\")\n",
    "\n",
    "    for filename in files_to_download:\n",
    "        url = base_url + filename\n",
    "        \n",
    "        gz_path = os.path.join(output_dir, filename)\n",
    "        \n",
    "        tsv_path = gz_path.replace(\".gz\", \"\")\n",
    "        \n",
    "        try:\n",
    "            print(f\"\\nBaixando: {filename}...\")\n",
    "            with requests.get(url, stream=True) as r:\n",
    "                r.raise_for_status() # Lan√ßa um erro se o status n√£o for 200\n",
    "                with open(gz_path, 'wb') as f:\n",
    "                    for chunk in r.iter_content(chunk_size=8192): \n",
    "                        f.write(chunk)\n",
    "            print(\"Download conclu√≠do.\")\n",
    "\n",
    "            print(f\"Descomprimindo: {filename}...\")\n",
    "            with gzip.open(gz_path, 'rb') as f_in:\n",
    "                with open(tsv_path, 'wb') as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)\n",
    "            print(f\"Arquivo salvo: {tsv_path}\")\n",
    "            \n",
    "            os.remove(gz_path)\n",
    "            print(f\"Arquivo tempor√°rio '{gz_path}' removido.\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"\\nERRO: Falha ao baixar {url}. Motivo: {e}\")\n",
    "            print(\"Por favor, verifique sua conex√£o ou a URL.\")\n",
    "            if os.path.exists(gz_path):\n",
    "                os.remove(gz_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nERRO: Ocorreu um problema: {e}\")\n",
    "\n",
    "    print(f\"\\nProcesso conclu√≠do! Os arquivos TSV est√£o em: '{output_dir}'\")\n",
    "\n",
    "baixar_e_descomprimir_imdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f215ab55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Informa√ß√µes do DataFrame consolidado:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "      <th>streaming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s1</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Dick Johnson Is Dead</td>\n",
       "      <td>Kirsten Johnson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>2021-09-25</td>\n",
       "      <td>2020</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>90 min</td>\n",
       "      <td>Documentaries</td>\n",
       "      <td>As her father nears the end of his life, filmm...</td>\n",
       "      <td>Netflix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s2</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Blood &amp; Water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>2021-09-24</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>2 Seasons</td>\n",
       "      <td>International TV Shows, TV Dramas, TV Mysteries</td>\n",
       "      <td>After crossing paths at a party, a Cape Town t...</td>\n",
       "      <td>Netflix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Ganglands</td>\n",
       "      <td>Julien Leclercq</td>\n",
       "      <td>Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-09-24</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>Crime TV Shows, International TV Shows, TV Act...</td>\n",
       "      <td>To protect his family from a powerful drug lor...</td>\n",
       "      <td>Netflix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s4</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Jailbirds New Orleans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-09-24</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>Docuseries, Reality TV</td>\n",
       "      <td>Feuds, flirtations and toilet talk go down amo...</td>\n",
       "      <td>Netflix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s5</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Kota Factory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mayur More, Jitendra Kumar, Ranjan Raj, Alam K...</td>\n",
       "      <td>India</td>\n",
       "      <td>2021-09-24</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>2 Seasons</td>\n",
       "      <td>International TV Shows, Romantic TV Shows, TV ...</td>\n",
       "      <td>In a city of coaching centers known to train I...</td>\n",
       "      <td>Netflix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  show_id     type                  title         director  \\\n",
       "0      s1    Movie   Dick Johnson Is Dead  Kirsten Johnson   \n",
       "1      s2  TV Show          Blood & Water              NaN   \n",
       "2      s3  TV Show              Ganglands  Julien Leclercq   \n",
       "3      s4  TV Show  Jailbirds New Orleans              NaN   \n",
       "4      s5  TV Show           Kota Factory              NaN   \n",
       "\n",
       "                                                cast        country  \\\n",
       "0                                                NaN  United States   \n",
       "1  Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...   South Africa   \n",
       "2  Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...            NaN   \n",
       "3                                                NaN            NaN   \n",
       "4  Mayur More, Jitendra Kumar, Ranjan Raj, Alam K...          India   \n",
       "\n",
       "  date_added  release_year rating   duration  \\\n",
       "0 2021-09-25          2020  PG-13     90 min   \n",
       "1 2021-09-24          2021  TV-MA  2 Seasons   \n",
       "2 2021-09-24          2021  TV-MA   1 Season   \n",
       "3 2021-09-24          2021  TV-MA   1 Season   \n",
       "4 2021-09-24          2021  TV-MA  2 Seasons   \n",
       "\n",
       "                                           listed_in  \\\n",
       "0                                      Documentaries   \n",
       "1    International TV Shows, TV Dramas, TV Mysteries   \n",
       "2  Crime TV Shows, International TV Shows, TV Act...   \n",
       "3                             Docuseries, Reality TV   \n",
       "4  International TV Shows, Romantic TV Shows, TV ...   \n",
       "\n",
       "                                         description streaming  \n",
       "0  As her father nears the end of his life, filmm...   Netflix  \n",
       "1  After crossing paths at a party, a Cape Town t...   Netflix  \n",
       "2  To protect his family from a powerful drug lor...   Netflix  \n",
       "3  Feuds, flirtations and toilet talk go down amo...   Netflix  \n",
       "4  In a city of coaching centers known to train I...   Netflix  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenar as base de dados \n",
    "\n",
    "current_directory = os.getcwd() \n",
    "DESTINATION_DIR = os.path.join(current_directory, \"data\") \n",
    "\n",
    "df_netflix = pd.read_csv(os.path.join(DESTINATION_DIR, 'netflix_titles.csv'))\n",
    "df_disney = pd.read_csv(os.path.join(DESTINATION_DIR, 'disney_plus_titles.csv'))\n",
    "df_amazon = pd.read_csv(os.path.join(DESTINATION_DIR, 'amazon_prime_titles.csv'))\n",
    "\n",
    "df_netflix['streaming'] = 'Netflix'\n",
    "df_disney['streaming'] = 'Disney+'\n",
    "df_amazon['streaming'] = 'Prime Video'\n",
    "\n",
    "dataframes_to_concat = [df_netflix, df_disney, df_amazon]\n",
    "\n",
    "df_streaming = pd.concat(dataframes_to_concat, ignore_index=True)\n",
    "\n",
    "df_streaming['date_added'] = df_streaming['date_added'].str.strip()\n",
    "\n",
    "df_streaming['date_added'] = pd.to_datetime(df_streaming['date_added'], format='%B %d, %Y')\n",
    "\n",
    "# Exibindo informa√ß√µes gerais para confirmar a jun√ß√£o e os tipos de dados\n",
    "print(\"\\nInforma√ß√µes do DataFrame consolidado:\")\n",
    "df_streaming.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cc2033c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento conclu√≠do. Exemplo do resultado:\n",
      "                                           listed_in  \\\n",
      "0                                      Documentaries   \n",
      "1    International TV Shows, TV Dramas, TV Mysteries   \n",
      "2  Crime TV Shows, International TV Shows, TV Act...   \n",
      "3                             Docuseries, Reality TV   \n",
      "4  International TV Shows, Romantic TV Shows, TV ...   \n",
      "5                 TV Dramas, TV Horror, TV Mysteries   \n",
      "6                           Children & Family Movies   \n",
      "7   Dramas, Independent Movies, International Movies   \n",
      "8                       British TV Shows, Reality TV   \n",
      "9                                   Comedies, Dramas   \n",
      "\n",
      "                          genres_processed  \n",
      "0                              Documentary  \n",
      "1            Drama, International, Mystery  \n",
      "2  Action, Adventure, Crime, International  \n",
      "3                     Documentary, Reality  \n",
      "4           Comedy, International, Romance  \n",
      "5                   Drama, Horror, Mystery  \n",
      "6                             Family, Kids  \n",
      "7        Drama, Independent, International  \n",
      "8                      British TV, Reality  \n",
      "9                            Comedy, Drama  \n",
      "show_id                     object\n",
      "type                        object\n",
      "title                       object\n",
      "director                    object\n",
      "cast                        object\n",
      "country                     object\n",
      "date_added          datetime64[ns]\n",
      "release_year                 int64\n",
      "rating                      object\n",
      "duration                    object\n",
      "listed_in                   object\n",
      "description                 object\n",
      "streaming                   object\n",
      "genres_processed            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "genre_mapping = {\n",
    "    # --- PADRONIZA√á√ÉO E CONSOLIDA√á√ÉO (TV/Filmes -> G√™nero Principal) ---\n",
    "    'Dramas': 'Drama', 'TV Dramas': 'Drama',\n",
    "    'Comedies': 'Comedy', 'TV Comedies': 'Comedy', 'Romantic Comedy': 'Romance , Comedy',\n",
    "    'Thrillers': 'Thriller', 'TV Thrillers': 'Thriller',\n",
    "    'Documentaries': 'Documentary', 'Docuseries': 'Documentary',\n",
    "    'Horror Movies': 'Horror', 'TV Horror': 'Horror',\n",
    "    'Romantic Movies': 'Romance', 'Romantic TV Shows': 'Romance',\n",
    "    'International Movies': 'International', 'International TV Shows': 'International',\n",
    "    'Independent Movies': 'Independent',\n",
    "    'Sports Movies': 'Sports',\n",
    "    'Classic Movies': 'Classic',\n",
    "    'Cult Movies': 'Cult',\n",
    "    'LGBTQ Movies': 'LGBTQ',\n",
    "    'Crime TV Shows': 'Crime',\n",
    "    'Reality TV': 'Reality',\n",
    "    'Teen TV Shows': 'Teen',\n",
    "    'TV Mysteries': 'Mystery',\n",
    "    'Science Fiction': 'Sci-Fi',\n",
    "\n",
    "    # --- MAPEAMENTO DE SIN√îNIMOS E SUB-G√äNEROS ---\n",
    "    'Anime Features': 'Anime', 'Anime Series': 'Anime',\n",
    "    \"Kids' TV\": \"Kids\", 'Children & Family Movies': 'Kids, Family',\n",
    "    'Faith and Spirituality': 'Faith & Spirituality',\n",
    "    'Young Adult Audience': 'Young Adult',\n",
    "    'Soap Opera / Melodrama': 'Soap Opera',\n",
    "    'and Culture': 'Culture', \n",
    "\n",
    "    # --- SEPARA√á√ÉO DE G√äNEROS COMPOSTOS (usando v√≠rgula) ---\n",
    "    'Animals & Nature': 'Nature',\n",
    "    'Science & Nature': 'Nature, Science', \n",
    "    'Arts & Culture': 'Culture, Art',\n",
    "    'Action & Adventure': 'Action, Adventure',\n",
    "    'Sci-Fi & Fantasy': 'Sci-Fi, Fantasy',\n",
    "    'Stand-Up Comedy & Talk Shows': 'Stand-Up Comedy, Talk Show',\n",
    "    'Music Videos and Concerts': 'Music',\n",
    "    'Music & Musicals': 'Music, Musical',\n",
    "    'Science & Nature TV': 'Science, Nature',\n",
    "    'Animals & Nature': 'Animals, Nature',\n",
    "    'TV Action & Adventure': 'Action, Adventure',\n",
    "    'TV Sci-Fi & Fantasy': 'Sci-Fi, Fantasy',\n",
    "    'Game Show / Competition': 'Game Show, Competition',\n",
    "    'Action-Adventure': 'Action, Adventure',\n",
    "    'Classic & Cult TV': 'Classic, Cult',\n",
    "    'Talk Show and Variety': 'Talk Show, Variety',\n",
    "    \n",
    "    # --- Mapeamento direto de g√™neros de TV para manter a distin√ß√£o se desejado ---\n",
    "    'Korean TV Shows': 'Korean TV',\n",
    "    'British TV Shows': 'British TV',\n",
    "    'Spanish-Language TV Shows': 'Spanish TV',\n",
    "\n",
    "    # --- Remo√ß√£o de Formatos (n√£o s√£o g√™neros tem√°ticos) ---\n",
    "    'Movies': '_REMOVE_',\n",
    "    'Series': '_REMOVE_',\n",
    "    'TV Shows': '_REMOVE_', \n",
    "    'TV Show': '_REMOVE_',\n",
    "    'Anthology': '_REMOVE_',\n",
    "    'Unscripted': '_REMOVE_', # Categoria muito ampla, coberta por Reality\n",
    "    'Special Interest': '_REMOVE_' # Categoria muito gen√©rica\n",
    "}\n",
    "\n",
    "def process_genres(genre_string):\n",
    "    \"\"\"\n",
    "    Fun√ß√£o para aplicar o mapeamento de g√™nero em uma string \n",
    "    que pode conter m√∫ltiplos g√™neros.\n",
    "    \"\"\"\n",
    "    if pd.isna(genre_string):\n",
    "        return '' # Retorna string vazia \n",
    "\n",
    "    processed_genres = set()\n",
    "    \n",
    "    # 1. Separa os g√™neros da string original (ex: \"TV Dramas, TV Mysteries\")\n",
    "    initial_genres = genre_string.split(',')\n",
    "\n",
    "    for genre in initial_genres:\n",
    "        # 2. Limpa o whitespace (ex: \" TV Dramas\" -> \"TV Dramas\")\n",
    "        clean_genre = genre.strip()\n",
    "\n",
    "        # 3. Aplica o mapping. \n",
    "        mapped_value = genre_mapping.get(clean_genre, clean_genre)\n",
    "\n",
    "        # 4. Processa o valor mapeado\n",
    "        if mapped_value == '_REMOVE_':\n",
    "            # N√£o faz nada, simplesmente ignora o g√™nero\n",
    "            continue\n",
    "        elif ',' in mapped_value:\n",
    "            # Separa, limpa e adiciona cada sub-g√™nero\n",
    "            sub_genres = mapped_value.split(',')\n",
    "            for sub in sub_genres:\n",
    "                processed_genres.add(sub.strip())\n",
    "        else:\n",
    "            # √â um valor √∫nico, n√£o vazio e n√£o _REMOVE_\n",
    "            if mapped_value:\n",
    "                processed_genres.add(mapped_value)\n",
    "    \n",
    "    # ordenados alfabeticamente para consist√™ncia.\n",
    "    return ', '.join(sorted(list(processed_genres)))\n",
    "\n",
    "df_streaming['genres_processed'] = df_streaming['listed_in'].apply(process_genres)\n",
    "\n",
    "# 4. (Opcional) Mostra o resultado das 10 primeiras linhas\n",
    "print(\"Processamento conclu√≠do. Exemplo do resultado:\")\n",
    "print(df_streaming[['listed_in', 'genres_processed']].head(10))\n",
    "\n",
    "print(df_streaming.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c938e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_file = os.path.join('data', 'filmes_series.csv')\n",
    "df_streaming.to_csv(output_csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30a73cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executando a consulta de 'merge' (isso pode levar alguns minutos)...\n",
      "\n",
      "Sucesso! Arquivo salvo como: 'data\\filmes_series_imdb.csv'\n",
      "Verificando quantos t√≠tulos conseguimos concatenar...\n",
      "\n",
      "--- Relat√≥rio de Concatena√ß√£o ---\n",
      "Total de t√≠tulos no seu CSV: 19925\n",
      "T√≠tulos que receberam nota do IMDb: 14216\n",
      "Taxa de sucesso da concatena√ß√£o: 71.35%\n"
     ]
    }
   ],
   "source": [
    "imdb_data_dir = 'data'\n",
    "basics_tsv = os.path.join(imdb_data_dir, 'title.basics.tsv')\n",
    "ratings_tsv = os.path.join(imdb_data_dir, 'title.ratings.tsv')\n",
    "crew_tsv = os.path.join(imdb_data_dir, 'title.crew.tsv')\n",
    "names_tsv = os.path.join(imdb_data_dir, 'name.basics.tsv')\n",
    "movies_csv_file = os.path.join(imdb_data_dir, 'filmes_series.csv')\n",
    "output_csv_file = os.path.join(imdb_data_dir, 'filmes_series_imdb.csv')\n",
    "\n",
    "con = duckdb.connect(database=':memory:', read_only=False)\n",
    "\n",
    "# --- Consulta SQL Principal ---\n",
    "# Esta consulta √© longa, pois prepara e junta 5 arquivos diferentes.\n",
    "# Consulta desenvolvida com auxilio de IA\n",
    "merge_query = f\"\"\"\n",
    "WITH\n",
    "-- 1. Prepara a base de T√≠tulos e Notas do IMDb\n",
    "imdb_titles_with_rating AS (\n",
    "    SELECT\n",
    "        basics.tconst,\n",
    "        basics.primaryTitle,\n",
    "        basics.titleType,\n",
    "        ratings.averageRating,\n",
    "        TRY_CAST(basics.startYear AS INT64) AS startYear\n",
    "    FROM read_csv_auto('{basics_tsv}', header=True, delim='\\t', quote='', strict_mode=False) AS basics\n",
    "    JOIN read_csv_auto('{ratings_tsv}', header=True, delim='\\t', quote='') AS ratings\n",
    "        ON basics.tconst = ratings.tconst\n",
    "    WHERE basics.titleType IN ('movie', 'tvSeries', 'tvMiniSeries', 'tvMovie')\n",
    "),\n",
    "\n",
    "-- 2. Prepara a base de Diretores do IMDb \n",
    "imdb_director_names AS (\n",
    "    SELECT\n",
    "        crew.tconst,\n",
    "        names.primaryName AS imdb_director_name\n",
    "    FROM read_csv_auto('{crew_tsv}', header=True, delim='\\t', quote='') AS crew\n",
    "    CROSS JOIN unnest(string_split(crew.directors, ',')) AS t(nconst_id)\n",
    "    JOIN read_csv_auto('{names_tsv}', header=True, delim='\\t', quote='', strict_mode=False) AS names\n",
    "        ON names.nconst = t.nconst_id\n",
    "    WHERE t.nconst_id != '\\\\N'\n",
    "),\n",
    "\n",
    "-- 3. Junta T√≠tulos, Notas e Nomes de Diretores do IMDb \n",
    "imdb_full_directors AS (\n",
    "    SELECT\n",
    "        LOWER(TRIM(t.primaryTitle)) AS imdb_title_clean,\n",
    "        LOWER(TRIM(d.imdb_director_name)) AS imdb_director_clean,\n",
    "        t.averageRating AS imdb_rating\n",
    "    FROM imdb_titles_with_rating AS t\n",
    "    JOIN imdb_director_names AS d ON t.tconst = d.tconst\n",
    "    GROUP BY 1, 2, 3\n",
    "),\n",
    "\n",
    "-- 4. Prepara a base de dados (sem altera√ß√£o, com UNION ALL)\n",
    "netflix_directors_exploded AS (\n",
    "    SELECT\n",
    "        n.*, \n",
    "        LOWER(TRIM(director_name)) AS director_clean,\n",
    "        LOWER(TRIM(title)) AS title_clean\n",
    "    FROM read_csv_auto('{movies_csv_file}', header=True, auto_detect=True) AS n\n",
    "    CROSS JOIN unnest(string_split(n.director, ',')) AS t(director_name)\n",
    "    WHERE n.director IS NOT NULL\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        n.*, \n",
    "        NULL AS director_clean, \n",
    "        LOWER(TRIM(title)) AS title_clean\n",
    "    FROM read_csv_auto('{movies_csv_file}', header=True, auto_detect=True) AS n\n",
    "    WHERE n.director IS NULL\n",
    "),\n",
    "\n",
    "-- 5. Prepara a base do IMDb para jun√ß√£o por T√≠tulo + Ano\n",
    "imdb_full_year AS (\n",
    "    SELECT\n",
    "        LOWER(TRIM(primaryTitle)) AS imdb_title_clean,\n",
    "        startYear,\n",
    "        AVG(averageRating) AS imdb_rating -- M√©dia caso haja duplicatas (raro)\n",
    "    FROM imdb_titles_with_rating\n",
    "    GROUP BY 1, 2\n",
    ")\n",
    "\n",
    "\n",
    "-- 6. Consulta Final: Junta dataset com IMDb \n",
    "SELECT\n",
    "    n.show_id,\n",
    "    n.type,\n",
    "    n.title,\n",
    "    n.director,\n",
    "    n.cast,\n",
    "    n.country,\n",
    "    n.date_added,\n",
    "    n.release_year,\n",
    "    n.rating,\n",
    "    n.duration,\n",
    "    n.listed_in,\n",
    "    n.description,\n",
    "    n.genres_processed,\n",
    "    n.streaming,\n",
    "    \n",
    "    -- COALESCE usa a primeira nota que n√£o for NULA\n",
    "    COALESCE(\n",
    "        AVG(i_director.imdb_rating), -- 1¬™ Tentativa: T√≠tulo + Diretor\n",
    "        AVG(i_year.imdb_rating)      -- 2¬™ Tentativa: T√≠tulo + Ano\n",
    "    ) AS imdb_rating_concatenada\n",
    "    \n",
    "FROM netflix_directors_exploded AS n\n",
    "-- JOIN 1: T√≠tulo + Diretor (Alta Precis√£o)\n",
    "LEFT JOIN imdb_full_directors AS i_director\n",
    "    ON n.title_clean = i_director.imdb_title_clean\n",
    "    AND n.director_clean = i_director.imdb_director_clean\n",
    "\n",
    "-- JOIN 2: T√≠tulo + Ano (M√©dia Precis√£o)\n",
    "LEFT JOIN imdb_full_year AS i_year\n",
    "    ON n.title_clean = i_year.imdb_title_clean\n",
    "    AND jaro_winkler_similarity(n.title_clean, i_year.imdb_title_clean) > 0.8\n",
    "\n",
    "GROUP BY\n",
    "    n.show_id, n.type, n.title, n.director, n.cast, n.country,\n",
    "    n.date_added, n.release_year, n.rating, n.duration,\n",
    "    n.listed_in, n.description, n.streaming, n.genres_processed\n",
    "\n",
    "HAVING\n",
    "    COALESCE(AVG(i_director.imdb_rating), AVG(i_year.imdb_rating)) IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "print(\"Executando a consulta de 'merge' (isso pode levar alguns minutos)...\")\n",
    "# Executa a consulta e salva o resultado em um novo CSV\n",
    "con.execute(f\"\"\"\n",
    "    COPY ({merge_query})\n",
    "    TO '{output_csv_file}'\n",
    "    WITH (HEADER 1, DELIMITER ',')\n",
    "\"\"\")\n",
    "print(f\"\\nSucesso! Arquivo salvo como: '{output_csv_file}'\")\n",
    "\n",
    "# --- Verifica√ß√£o ---\n",
    "print(\"Verificando quantos t√≠tulos conseguimos concatenar...\")\n",
    "\n",
    "result = con.execute(f\"\"\"\n",
    "    SELECT\n",
    "        COUNT(*) AS total_titulos,\n",
    "        COUNT(imdb_rating_concatenada) AS titulos_com_nota\n",
    "    FROM read_csv_auto('{output_csv_file}', header=True)\n",
    "\"\"\").df()\n",
    "\n",
    "total = df_streaming.shape[0]\n",
    "matched = result['titulos_com_nota'].iloc[0]\n",
    "percent = (matched / total) * 100 if total > 0 else 0\n",
    "\n",
    "print(\"\\n--- Relat√≥rio de Concatena√ß√£o ---\")\n",
    "print(f\"Total de t√≠tulos no seu CSV: {total}\")\n",
    "print(f\"T√≠tulos que receberam nota do IMDb: {matched}\")\n",
    "print(f\"Taxa de sucesso da concatena√ß√£o: {percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b06efe",
   "metadata": {},
   "source": [
    "# Etapa 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0840c9",
   "metadata": {},
   "source": [
    "### Transforma√ß√£o Tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2673bdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19925 entries, 0 to 19924\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   show_id           19925 non-null  object        \n",
      " 1   type              19925 non-null  object        \n",
      " 2   title             19925 non-null  object        \n",
      " 3   director          14735 non-null  object        \n",
      " 4   cast              17677 non-null  object        \n",
      " 5   country           9879 non-null   object        \n",
      " 6   date_added        10399 non-null  datetime64[ns]\n",
      " 7   release_year      19925 non-null  int64         \n",
      " 8   rating            19581 non-null  object        \n",
      " 9   duration          19922 non-null  object        \n",
      " 10  listed_in         19925 non-null  object        \n",
      " 11  description       19925 non-null  object        \n",
      " 12  streaming         19925 non-null  object        \n",
      " 13  genres_processed  19925 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(12)\n",
      "memory usage: 2.1+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14216 entries, 0 to 14215\n",
      "Data columns (total 78 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   show_id                     14216 non-null  object \n",
      " 1   type                        14216 non-null  object \n",
      " 2   title                       14216 non-null  object \n",
      " 3   director                    10644 non-null  object \n",
      " 4   cast                        13086 non-null  object \n",
      " 5   country                     7863 non-null   object \n",
      " 6   date_added                  7892 non-null   object \n",
      " 7   release_year                14216 non-null  int64  \n",
      " 8   rating                      14008 non-null  object \n",
      " 9   duration                    14216 non-null  object \n",
      " 10  listed_in                   14216 non-null  object \n",
      " 11  description                 14216 non-null  object \n",
      " 12  genres_processed            14216 non-null  object \n",
      " 13  streaming                   14216 non-null  object \n",
      " 14  imdb_rating_concatenada     14216 non-null  float64\n",
      " 15  Genre_Action                14216 non-null  int64  \n",
      " 16  Genre_Adventure             14216 non-null  int64  \n",
      " 17  Genre_Animals               14216 non-null  int64  \n",
      " 18  Genre_Animation             14216 non-null  int64  \n",
      " 19  Genre_Anime                 14216 non-null  int64  \n",
      " 20  Genre_Arthouse              14216 non-null  int64  \n",
      " 21  Genre_Arts                  14216 non-null  int64  \n",
      " 22  Genre_Biographical          14216 non-null  int64  \n",
      " 23  Genre_British TV            14216 non-null  int64  \n",
      " 24  Genre_Buddy                 14216 non-null  int64  \n",
      " 25  Genre_Classic               14216 non-null  int64  \n",
      " 26  Genre_Comedy                14216 non-null  int64  \n",
      " 27  Genre_Coming of Age         14216 non-null  int64  \n",
      " 28  Genre_Competition           14216 non-null  int64  \n",
      " 29  Genre_Concert Film          14216 non-null  int64  \n",
      " 30  Genre_Crime                 14216 non-null  int64  \n",
      " 31  Genre_Cult                  14216 non-null  int64  \n",
      " 32  Genre_Culture               14216 non-null  int64  \n",
      " 33  Genre_Dance                 14216 non-null  int64  \n",
      " 34  Genre_Disaster              14216 non-null  int64  \n",
      " 35  Genre_Documentary           14216 non-null  int64  \n",
      " 36  Genre_Drama                 14216 non-null  int64  \n",
      " 37  Genre_Entertainment         14216 non-null  int64  \n",
      " 38  Genre_Faith & Spirituality  14216 non-null  int64  \n",
      " 39  Genre_Family                14216 non-null  int64  \n",
      " 40  Genre_Fantasy               14216 non-null  int64  \n",
      " 41  Genre_Fitness               14216 non-null  int64  \n",
      " 42  Genre_Game Show             14216 non-null  int64  \n",
      " 43  Genre_Historical            14216 non-null  int64  \n",
      " 44  Genre_Horror                14216 non-null  int64  \n",
      " 45  Genre_Independent           14216 non-null  int64  \n",
      " 46  Genre_International         14216 non-null  int64  \n",
      " 47  Genre_Kids                  14216 non-null  int64  \n",
      " 48  Genre_Korean TV             14216 non-null  int64  \n",
      " 49  Genre_LGBTQ                 14216 non-null  int64  \n",
      " 50  Genre_Lifestyle             14216 non-null  int64  \n",
      " 51  Genre_Medical               14216 non-null  int64  \n",
      " 52  Genre_Military and War      14216 non-null  int64  \n",
      " 53  Genre_Music                 14216 non-null  int64  \n",
      " 54  Genre_Musical               14216 non-null  int64  \n",
      " 55  Genre_Mystery               14216 non-null  int64  \n",
      " 56  Genre_Nature                14216 non-null  int64  \n",
      " 57  Genre_Parody                14216 non-null  int64  \n",
      " 58  Genre_Reality               14216 non-null  int64  \n",
      " 59  Genre_Romance               14216 non-null  int64  \n",
      " 60  Genre_Sci-Fi                14216 non-null  int64  \n",
      " 61  Genre_Science               14216 non-null  int64  \n",
      " 62  Genre_Soap Opera            14216 non-null  int64  \n",
      " 63  Genre_Spanish TV            14216 non-null  int64  \n",
      " 64  Genre_Sports                14216 non-null  int64  \n",
      " 65  Genre_Spy/Espionage         14216 non-null  int64  \n",
      " 66  Genre_Stand-Up Comedy       14216 non-null  int64  \n",
      " 67  Genre_Superhero             14216 non-null  int64  \n",
      " 68  Genre_Survival              14216 non-null  int64  \n",
      " 69  Genre_Suspense              14216 non-null  int64  \n",
      " 70  Genre_Talk Show             14216 non-null  int64  \n",
      " 71  Genre_Teen                  14216 non-null  int64  \n",
      " 72  Genre_Thriller              14216 non-null  int64  \n",
      " 73  Genre_Travel                14216 non-null  int64  \n",
      " 74  Genre_Unknown               14216 non-null  int64  \n",
      " 75  Genre_Variety               14216 non-null  int64  \n",
      " 76  Genre_Western               14216 non-null  int64  \n",
      " 77  Genre_Young Adult           14216 non-null  int64  \n",
      "dtypes: float64(1), int64(64), object(13)\n",
      "memory usage: 8.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_streaming.info()\n",
    "\n",
    "output_csv_file = os.path.join(imdb_data_dir, 'filmes_series_imdb.csv')\n",
    "df_streaming_completo = pd.read_csv(output_csv_file)\n",
    "\n",
    "#Dividir generos em varios booleanos\n",
    "df_streaming_completo['genres_processed'] = df_streaming_completo['genres_processed'].fillna('Unknown')\n",
    "genre_dummies = df_streaming_completo['genres_processed'].str.get_dummies(sep=', ')\n",
    "genre_dummies = genre_dummies.add_prefix('Genre_')\n",
    "df_streaming_completo = pd.concat([df_streaming_completo, genre_dummies], axis=1)\n",
    "df_streaming_completo.to_csv(output_csv_file)\n",
    "\n",
    "df_streaming_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fad9548c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7863 entries, 0 to 14215\n",
      "Data columns (total 79 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Unnamed: 0                  7863 non-null   int64  \n",
      " 1   show_id                     7863 non-null   object \n",
      " 2   type                        7863 non-null   object \n",
      " 3   title                       7863 non-null   object \n",
      " 4   director                    5684 non-null   object \n",
      " 5   cast                        7272 non-null   object \n",
      " 6   country                     7863 non-null   object \n",
      " 7   date_added                  7292 non-null   object \n",
      " 8   release_year                7863 non-null   int64  \n",
      " 9   rating                      7848 non-null   object \n",
      " 10  duration                    7863 non-null   object \n",
      " 11  listed_in                   7863 non-null   object \n",
      " 12  description                 7863 non-null   object \n",
      " 13  genres_processed            7863 non-null   object \n",
      " 14  streaming                   7863 non-null   object \n",
      " 15  imdb_rating_concatenada     7863 non-null   float64\n",
      " 16  Genre_Action                7863 non-null   int64  \n",
      " 17  Genre_Adventure             7863 non-null   int64  \n",
      " 18  Genre_Animals               7863 non-null   int64  \n",
      " 19  Genre_Animation             7863 non-null   int64  \n",
      " 20  Genre_Anime                 7863 non-null   int64  \n",
      " 21  Genre_Arthouse              7863 non-null   int64  \n",
      " 22  Genre_Arts                  7863 non-null   int64  \n",
      " 23  Genre_Biographical          7863 non-null   int64  \n",
      " 24  Genre_British TV            7863 non-null   int64  \n",
      " 25  Genre_Buddy                 7863 non-null   int64  \n",
      " 26  Genre_Classic               7863 non-null   int64  \n",
      " 27  Genre_Comedy                7863 non-null   int64  \n",
      " 28  Genre_Coming of Age         7863 non-null   int64  \n",
      " 29  Genre_Competition           7863 non-null   int64  \n",
      " 30  Genre_Concert Film          7863 non-null   int64  \n",
      " 31  Genre_Crime                 7863 non-null   int64  \n",
      " 32  Genre_Cult                  7863 non-null   int64  \n",
      " 33  Genre_Culture               7863 non-null   int64  \n",
      " 34  Genre_Dance                 7863 non-null   int64  \n",
      " 35  Genre_Disaster              7863 non-null   int64  \n",
      " 36  Genre_Documentary           7863 non-null   int64  \n",
      " 37  Genre_Drama                 7863 non-null   int64  \n",
      " 38  Genre_Entertainment         7863 non-null   int64  \n",
      " 39  Genre_Faith & Spirituality  7863 non-null   int64  \n",
      " 40  Genre_Family                7863 non-null   int64  \n",
      " 41  Genre_Fantasy               7863 non-null   int64  \n",
      " 42  Genre_Fitness               7863 non-null   int64  \n",
      " 43  Genre_Game Show             7863 non-null   int64  \n",
      " 44  Genre_Historical            7863 non-null   int64  \n",
      " 45  Genre_Horror                7863 non-null   int64  \n",
      " 46  Genre_Independent           7863 non-null   int64  \n",
      " 47  Genre_International         7863 non-null   int64  \n",
      " 48  Genre_Kids                  7863 non-null   int64  \n",
      " 49  Genre_Korean TV             7863 non-null   int64  \n",
      " 50  Genre_LGBTQ                 7863 non-null   int64  \n",
      " 51  Genre_Lifestyle             7863 non-null   int64  \n",
      " 52  Genre_Medical               7863 non-null   int64  \n",
      " 53  Genre_Military and War      7863 non-null   int64  \n",
      " 54  Genre_Music                 7863 non-null   int64  \n",
      " 55  Genre_Musical               7863 non-null   int64  \n",
      " 56  Genre_Mystery               7863 non-null   int64  \n",
      " 57  Genre_Nature                7863 non-null   int64  \n",
      " 58  Genre_Parody                7863 non-null   int64  \n",
      " 59  Genre_Reality               7863 non-null   int64  \n",
      " 60  Genre_Romance               7863 non-null   int64  \n",
      " 61  Genre_Sci-Fi                7863 non-null   int64  \n",
      " 62  Genre_Science               7863 non-null   int64  \n",
      " 63  Genre_Soap Opera            7863 non-null   int64  \n",
      " 64  Genre_Spanish TV            7863 non-null   int64  \n",
      " 65  Genre_Sports                7863 non-null   int64  \n",
      " 66  Genre_Spy/Espionage         7863 non-null   int64  \n",
      " 67  Genre_Stand-Up Comedy       7863 non-null   int64  \n",
      " 68  Genre_Superhero             7863 non-null   int64  \n",
      " 69  Genre_Survival              7863 non-null   int64  \n",
      " 70  Genre_Suspense              7863 non-null   int64  \n",
      " 71  Genre_Talk Show             7863 non-null   int64  \n",
      " 72  Genre_Teen                  7863 non-null   int64  \n",
      " 73  Genre_Thriller              7863 non-null   int64  \n",
      " 74  Genre_Travel                7863 non-null   int64  \n",
      " 75  Genre_Unknown               7863 non-null   int64  \n",
      " 76  Genre_Variety               7863 non-null   int64  \n",
      " 77  Genre_Western               7863 non-null   int64  \n",
      " 78  Genre_Young Adult           7863 non-null   int64  \n",
      "dtypes: float64(1), int64(65), object(13)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "def remover_nulos_por_coluna(caminho_csv, nomes_colunas):\n",
    "    \"\"\"\n",
    "    L√™ um arquivo CSV e retorna um DataFrame sem as linhas\n",
    "    onde a 'nomes_colunas' especificada est√° em branco (NaN ou string vazia).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. L√™ o arquivo CSV\n",
    "        df = pd.read_csv(caminho_csv)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERRO: O arquivo '{caminho_csv}' n√£o foi encontrado.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao ler o arquivo: {e}\")\n",
    "        return None\n",
    "\n",
    "    # 2. Verifica se a coluna existe no DataFrame\n",
    "    colunas_faltando = [col for col in nomes_colunas if col not in df.columns]\n",
    "    \n",
    "    if colunas_faltando:\n",
    "        print(f\"ERRO: As seguintes colunas n√£o foram encontradas: {colunas_faltando}\")\n",
    "        print(f\"Colunas dispon√≠veis: {df.columns.to_list()}\")\n",
    "        return None\n",
    "\n",
    "    # 3. Remove as linhas onde a coluna √© Nula (NaN, pd.NA, etc.)\n",
    "    df_limpo = df.dropna(subset=nomes_colunas)\n",
    "\n",
    "    # 5. Devolve o DataFrame limpo\n",
    "    return df_limpo\n",
    "\n",
    "#Teste\n",
    "df = remover_nulos_por_coluna(output_csv_file, ['country'])\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6355e83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando processamento da coluna 'country' no arquivo: data\\filmes_series_imdb.csv\n",
      "Criando colunas dummy para Pa√≠ses...\n",
      "Total de colunas ap√≥s adi√ß√£o dos Pa√≠ses: 205\n",
      "‚úÖ Arquivo CSV atualizado com sucesso. Total de colunas Country_: 126\n"
     ]
    }
   ],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = 'data'\n",
    "output_csv_file = os.path.join(imdb_data_dir, 'filmes_series_imdb.csv')\n",
    "\n",
    "print(f\"Iniciando processamento da coluna 'country' no arquivo: {output_csv_file}\")\n",
    "\n",
    "# 1. Carrega o DataFrame base\n",
    "try:\n",
    "    df_base = pd.read_csv(output_csv_file)\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: Arquivo '{output_csv_file}' n√£o encontrado. Verifique a conclus√£o das etapas anteriores.\")\n",
    "    exit()\n",
    "\n",
    "# 2. Pr√©-processamento: Trata valores nulos na coluna 'country'\n",
    "# Preenche NaN para que o get_dummies funcione\n",
    "df_base['country'] = df_base['country'].fillna('Unknown Country')\n",
    "\n",
    "# 3. Cria Dummies: Separa os pa√≠ses e cria colunas booleanas\n",
    "print(\"Criando colunas dummy para Pa√≠ses...\")\n",
    "country_dummies = df_base['country'].str.get_dummies(sep=', ')\n",
    "country_dummies = country_dummies.add_prefix('Country_')\n",
    "\n",
    "# 4. Concatena as Dummies de Pa√≠s com o DataFrame\n",
    "df_base = pd.concat([df_base, country_dummies], axis=1)\n",
    "print(f\"Total de colunas ap√≥s adi√ß√£o dos Pa√≠ses: {df_base.shape[1]}\")\n",
    "\n",
    "# 5. Salva o DataFrame ATUALIZADO (sobrescrevendo o arquivo CSV)\n",
    "df_base.to_csv(output_csv_file, index=False)\n",
    "\n",
    "print(f\"‚úÖ Arquivo CSV atualizado com sucesso. Total de colunas Country_: {country_dummies.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b03fb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tabela de Atores (Long) criada: 92446 linhas.\n",
      "‚úÖ Tabela de Diretores (Long) criada: 14821 linhas.\n",
      "‚úÖ Tabela Principal Tidy (Wide) criada: 8812 linhas, 201 colunas.\n",
      "\n",
      "üì¶ Exportando tabelas Tidy para o formato Parquet...\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müì¶ Exportando tabelas Tidy para o formato Parquet...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Tabela 1: Principal (Wide)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[43mdf_principal_tidy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimdb_data_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprincipal_tidy.parquet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m   - principal_tidy.parquet (Tabela Principal com Pa√≠ses/G√™neros Wide)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Tabela 2: Diretores (Long)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\Estudos\\Codigos\\CienciaDeDados\\ReposotorioDoGit\\TrabalhoFinal\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\Estudos\\Codigos\\CienciaDeDados\\ReposotorioDoGit\\TrabalhoFinal\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:3124\u001b[39m, in \u001b[36mDataFrame.to_parquet\u001b[39m\u001b[34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[39m\n\u001b[32m   3043\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3044\u001b[39m \u001b[33;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[32m   3045\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3120\u001b[39m \u001b[33;03m>>> content = f.read()\u001b[39;00m\n\u001b[32m   3121\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3122\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparquet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[32m-> \u001b[39m\u001b[32m3124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3125\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3132\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3133\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\Estudos\\Codigos\\CienciaDeDados\\ReposotorioDoGit\\TrabalhoFinal\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:478\u001b[39m, in \u001b[36mto_parquet\u001b[39m\u001b[34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(partition_cols, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    477\u001b[39m     partition_cols = [partition_cols]\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m impl = \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m path_or_buf: FilePath | WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] = io.BytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[32m    482\u001b[39m impl.write(\n\u001b[32m    483\u001b[39m     df,\n\u001b[32m    484\u001b[39m     path_or_buf,\n\u001b[32m   (...)\u001b[39m\u001b[32m    490\u001b[39m     **kwargs,\n\u001b[32m    491\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\Estudos\\Codigos\\CienciaDeDados\\ReposotorioDoGit\\TrabalhoFinal\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:68\u001b[39m, in \u001b[36mget_engine\u001b[39m\u001b[34m(engine)\u001b[39m\n\u001b[32m     65\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     66\u001b[39m             error_msgs += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m - \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(err)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     69\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnable to find a usable engine; \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtried using: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfastparquet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     71\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA suitable version of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     72\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msupport.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTrying to import the above resulted in these errors:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     75\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     76\u001b[39m     )\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[31mImportError\u001b[39m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = 'data'\n",
    "output_csv_file = os.path.join(imdb_data_dir, 'filmes_series_imdb.csv')\n",
    "\n",
    "# 1. Carrega o DataFrame base (agora com as colunas Country_ adicionadas pelo script anterior)\n",
    "try:\n",
    "    df_base = pd.read_csv(output_csv_file)\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: Arquivo '{output_csv_file}' n√£o encontrado. Verifique a execu√ß√£o do script de country.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. NORMALIZA√á√ÉO: Cria Tabelas Long (Alta Cardinalidade)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# --- A. Tabela de Elenco (Cast) Tidy (Formato Long) ---\n",
    "# Trata Nulos e explode\n",
    "df_cast = df_base[['show_id', 'cast']].copy()\n",
    "df_cast['cast'] = df_cast['cast'].fillna('Unknown') \n",
    "df_cast['cast_list'] = df_cast['cast'].str.split(', ')\n",
    "df_actors_tidy = df_cast.explode('cast_list').rename(columns={'cast_list': 'actor_name'})\n",
    "df_actors_tidy = df_actors_tidy[['show_id', 'actor_name']].drop_duplicates()\n",
    "print(f\"‚úÖ Tabela de Atores (Long) criada: {df_actors_tidy.shape[0]} linhas.\")\n",
    "\n",
    "\n",
    "# --- B. Tabela de Diretores (Director) Tidy (Formato Long) ---\n",
    "# Trata Nulos e explode\n",
    "df_director = df_base[['show_id', 'director']].copy()\n",
    "df_director['director'] = df_director['director'].fillna('Unknown')\n",
    "df_director['director_list'] = df_director['director'].str.split(', ')\n",
    "df_directors_tidy = df_director.explode('director_list').rename(columns={'director_list': 'director_name'})\n",
    "df_directors_tidy = df_directors_tidy[['show_id', 'director_name']].drop_duplicates()\n",
    "print(f\"‚úÖ Tabela de Diretores (Long) criada: {df_directors_tidy.shape[0]} linhas.\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. CRIA√á√ÉO DA TABELA PRINCIPAL Tidy (Wide)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# Colunas a SEREM REMOVIDAS da Tabela Principal Tidy:\n",
    "# 'cast', 'director', 'country' s√£o agora redundantes ou foram normalizadas\n",
    "columns_to_drop = [\n",
    "    'cast', 'director', 'country', 'listed_in' # 'listed_in' √© substitu√≠do por 'genres_processed'\n",
    "]\n",
    "\n",
    "# Usa .copy() para evitar SettingWithCopyWarning\n",
    "df_principal_tidy = df_base.drop(columns=columns_to_drop, errors='ignore').copy()\n",
    "\n",
    "# Remove a coluna tempor√°ria 'genres_processed' se preferir usar apenas as Dummies de G√™nero\n",
    "# df_principal_tidy = df_principal_tidy.drop(columns=['genres_processed'], errors='ignore')\n",
    "\n",
    "# Remove duplicatas baseadas no show_id (caso tenham entrado duplicatas na leitura do CSV)\n",
    "df_principal_tidy = df_principal_tidy.drop_duplicates(subset=['show_id']).reset_index(drop=True)\n",
    "print(f\"‚úÖ Tabela Principal Tidy (Wide) criada: {df_principal_tidy.shape[0]} linhas, {df_principal_tidy.shape[1]} colunas.\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 4. EXPORTA√á√ÉO PARA PARQUET\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "print(\"\\nüì¶ Exportando tabelas Tidy para o formato Parquet...\")\n",
    "\n",
    "# Tabela 1: Principal (Wide)\n",
    "df_principal_tidy.to_parquet(os.path.join(imdb_data_dir, 'principal_tidy.parquet'), index=False)\n",
    "print(\"   - principal_tidy.parquet (Tabela Principal com Pa√≠ses/G√™neros Wide)\")\n",
    "\n",
    "# Tabela 2: Diretores (Long)\n",
    "df_directors_tidy.to_parquet(os.path.join(imdb_data_dir, 'directors_tidy.parquet'), index=False)\n",
    "print(\"   - directors_tidy.parquet (Tabela de Diretores Long)\")\n",
    "\n",
    "# Tabela 3: Atores (Long)\n",
    "df_actors_tidy.to_parquet(os.path.join(imdb_data_dir, 'actors_tidy.parquet'), index=False)\n",
    "print(\"   - actors_tidy.parquet (Tabela de Atores Long)\")\n",
    "\n",
    "print(\"\\nüéâ Etapa Tidy Data conclu√≠da com sucesso. Seu projeto est√° pronto para as Consultas SQL!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93476d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data_dir = 'data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "directors_parquet = os.path.join(imdb_data_dir, 'directors_tidy.parquet')\n",
    "actors_parquet = os.path.join(imdb_data_dir, 'actors_tidy.parquet')\n",
    "output_csv_file = os.path.join(imdb_data_dir, 'principal_tidy.csv')\n",
    "\n",
    "try:\n",
    "    # 1. Carrega o arquivo Parquet Principal (Tabela Wide)\n",
    "    print(\"Carregando Tabela Principal (Parquet)...\")\n",
    "    df_principal = pd.read_parquet(principal_parquet)\n",
    "\n",
    "    # 2. Salva a Tabela Principal no formato CSV\n",
    "    df_principal.to_csv(output_csv_file, index=False)\n",
    "    print(f\"‚úÖ Tabela principal salva como CSV: {output_csv_file}\")\n",
    "    \n",
    "    # 3. Exibe um preview do DataFrame principal\n",
    "    print(\"\\n--- Preview da Tabela Principal Tidy (CSV) ---\")\n",
    "    print(df_principal.head())\n",
    "\n",
    "    # 4. Exibe um preview da Tabela de Diretores (Long)\n",
    "    print(\"\\n--- Preview da Tabela de Diretores Tidy ---\")\n",
    "    df_directors = pd.read_parquet(directors_parquet)\n",
    "    print(df_directors.head())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nERRO: Falha ao encontrar o arquivo. O Parquet precisa ser gerado primeiro. {e}\")\n",
    "    print(\"\\nPor favor, execute o c√≥digo da etapa Tidy anterior ('C√≥digo da Etapa Tidy Principal Atualizado') para gerar os arquivos Parquet, e depois execute este c√≥digo de visualiza√ß√£o.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db71162",
   "metadata": {},
   "source": [
    "### Consultas SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa6bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define o diret√≥rio e os nomes dos arquivos Parquet\n",
    "imdb_data_dir = 'data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "directors_parquet = os.path.join(imdb_data_dir, 'directors_tidy.parquet')\n",
    "actors_parquet = os.path.join(imdb_data_dir, 'actors_tidy.parquet')\n",
    "\n",
    "# 2. Conecta ao DuckDB\n",
    "con = duckdb.connect(database=':memory:', read_only=False)\n",
    "\n",
    "# Fun√ß√£o auxiliar para executar e formatar a sa√≠da\n",
    "def run_query(query_title, sql_query):\n",
    "    print(f\"\\n--- Consulta: {query_title} ---\")\n",
    "    try:\n",
    "        result = con.execute(sql_query).fetchdf()\n",
    "        print(result.to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao executar a consulta: {e}\")\n",
    "        print(\"Verifique se os nomes das colunas e arquivos Parquet est√£o corretos.\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# üéØ 1. Agrega√ß√£o e Compara√ß√£o: M√©dia de Nota por Servi√ßo de Streaming\n",
    "# (An√°lise Bivariada: streaming vs. imdb_rating_concatenada)\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_1 = f\"\"\"\n",
    "SELECT\n",
    "    streaming,\n",
    "    COUNT(show_id) AS total_titulos,\n",
    "    ROUND(AVG(imdb_rating_concatenada), 2) AS media_imdb_rating\n",
    "FROM '{principal_parquet}'\n",
    "GROUP BY 1\n",
    "ORDER BY media_imdb_rating DESC;\n",
    "\"\"\"\n",
    "run_query(\"1. Ranking de M√©dia de Nota por Streaming\", query_1)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# üéØ 2. Tend√™ncia Temporal: N√∫mero de T√≠tulos Lan√ßados por D√©cada\n",
    "# (An√°lise Temporal e de Distribui√ß√£o)\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_2 = f\"\"\"\n",
    "SELECT\n",
    "    (FLOOR(release_year / 10) * 10) AS decada_lancamento,\n",
    "    COUNT(show_id) AS total_titulos\n",
    "FROM '{principal_parquet}'\n",
    "WHERE release_year IS NOT NULL AND release_year >= 1950\n",
    "GROUP BY 1\n",
    "ORDER BY 1;\n",
    "\"\"\"\n",
    "run_query(\"2. Tend√™ncia de Lan√ßamento por D√©cada\", query_2)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# üéØ 3. Ranking com Agrega√ß√£o Complexa: Top 10 Diretores com Mais T√≠tulos e M√©dia de Nota\n",
    "# (Requer JOIN entre as tabelas Long e Wide)\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_3 = f\"\"\"\n",
    "WITH Director_Stats AS (\n",
    "    SELECT\n",
    "        t2.director_name,\n",
    "        COUNT(t1.show_id) AS num_titulos,\n",
    "        ROUND(AVG(t1.imdb_rating_concatenada), 2) AS media_rating\n",
    "    FROM '{principal_parquet}' AS t1\n",
    "    JOIN '{directors_parquet}' AS t2 ON t1.show_id = t2.show_id\n",
    "    WHERE t2.director_name != 'Unknown' AND t1.imdb_rating_concatenada IS NOT NULL\n",
    "    GROUP BY 1\n",
    ")\n",
    "SELECT\n",
    "    *,\n",
    "    RANK() OVER (ORDER BY num_titulos DESC) AS ranking_volume\n",
    "FROM Director_Stats\n",
    "WHERE num_titulos >= 5 -- Filtro para diretores relevantes\n",
    "ORDER BY num_titulos DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "run_query(\"3. Top 10 Diretores (Volume e M√©dia de Nota)\", query_3)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# üéØ 4. Correla√ß√£o: M√©dia de Nota IMDb por G√™nero\n",
    "# (An√°lise de correla√ß√£o usando colunas Wide/Dummy)\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_4 = f\"\"\"\n",
    "SELECT\n",
    "    'Documentary' AS genero,\n",
    "    ROUND(AVG(CASE WHEN \"Genre_Documentary\" = 1 THEN imdb_rating_concatenada ELSE NULL END), 2) AS media_rating\n",
    "FROM '{principal_parquet}'\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'Drama' AS genero,\n",
    "    ROUND(AVG(CASE WHEN \"Genre_Drama\" = 1 THEN imdb_rating_concatenada ELSE NULL END), 2) AS media_rating\n",
    "FROM '{principal_parquet}'\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'Kids' AS genero,\n",
    "    ROUND(AVG(CASE WHEN \"Genre_Kids\" = 1 THEN imdb_rating_concatenada ELSE NULL END), 2) AS media_rating\n",
    "FROM '{principal_parquet}'\n",
    "ORDER BY media_rating DESC;\n",
    "\"\"\"\n",
    "run_query(\"4. M√©dia de Nota dos G√™neros (Documentary, Drama, Kids)\", query_4)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# üéØ 5. An√°lise Bivariada: Pa√≠ses com Maior Nota M√©dia no IMDB\n",
    "# (Usa as colunas Country_ Dummy para agregar)\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_5 = f\"\"\"\n",
    "SELECT\n",
    "    'United States' AS country,\n",
    "    ROUND(AVG(CASE WHEN \"Country_United States\" = 1 THEN imdb_rating_concatenada ELSE NULL END), 2) AS media_rating\n",
    "FROM '{principal_parquet}'\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'India' AS country,\n",
    "    ROUND(AVG(CASE WHEN \"Country_India\" = 1 THEN imdb_rating_concatenada ELSE NULL END), 2) AS media_rating\n",
    "FROM '{principal_parquet}'\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'United Kingdom' AS country,\n",
    "    ROUND(AVG(CASE WHEN \"Country_United Kingdom\" = 1 THEN imdb_rating_concatenada ELSE NULL END), 2) AS media_rating\n",
    "FROM '{principal_parquet}'\n",
    "ORDER BY media_rating DESC;\n",
    "\"\"\"\n",
    "run_query(\"5. M√©dia de Nota dos 3 Principais Pa√≠ses de Origem\", query_5)\n",
    "\n",
    "# Fecha a conex√£o com o DuckDB\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5edf6cf",
   "metadata": {},
   "source": [
    "### An√°lise Univariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da74b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = 'data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "\n",
    "# 1. Carrega o DataFrame Principal\n",
    "try:\n",
    "    df_principal = pd.read_parquet(principal_parquet)\n",
    "except Exception as e:\n",
    "    print(f\"ERRO ao carregar o arquivo Parquet: {e}\")\n",
    "    print(\"Certifique-se de que o arquivo 'principal_tidy.parquet' foi gerado corretamente.\")\n",
    "    exit()\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# I. AN√ÅLISE DE VARI√ÅVEIS NUM√âRICAS (Medidas de Tend√™ncia Central e Dispers√£o)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "print(\"### I. An√°lise de Vari√°veis Num√©ricas (IMDb Rating e Ano de Lan√ßamento) ###\")\n",
    "\n",
    "# 1. Vari√°veis a serem analisadas\n",
    "numeric_cols = ['imdb_rating_concatenada', 'release_year']\n",
    "\n",
    "# 2. Gera√ß√£o da tabela de estat√≠sticas descritivas\n",
    "stats_descritivas = df_principal[numeric_cols].describe().T\n",
    "\n",
    "# Adiciona o c√°lculo da Moda (Mode)\n",
    "for col in numeric_cols:\n",
    "    stats_descritivas.loc[col, 'mode'] = df_principal[col].mode()[0]\n",
    "\n",
    "# Exibe o resultado formatado\n",
    "print(\"\\n[Medidas de Tend√™ncia Central e Dispers√£o]\")\n",
    "print(stats_descritivas[['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'mode']].to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# II. AN√ÅLISE DE VARI√ÅVEIS CATEG√ìRICAS (Distribui√ß√£o de Frequ√™ncia)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "print(\"\\n### II. An√°lise de Vari√°veis Categ√≥ricas (Distribui√ß√£o de Frequ√™ncia) ###\")\n",
    "\n",
    "# 1. Distribui√ß√£o de Frequ√™ncia: Tipo de T√≠tulo (Movie/TV Show)\n",
    "print(\"\\n[Distribui√ß√£o de Frequ√™ncia: Tipo de T√≠tulo]\")\n",
    "frequencia_type = df_principal['type'].value_counts(normalize=True).mul(100).round(2).reset_index()\n",
    "frequencia_type.columns = ['Tipo', 'Porcentagem']\n",
    "print(frequencia_type.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "\n",
    "# 2. Distribui√ß√£o de Frequ√™ncia: Servi√ßo de Streaming\n",
    "print(\"\\n[Distribui√ß√£o de Frequ√™ncia: Servi√ßo de Streaming]\")\n",
    "frequencia_streaming = df_principal['streaming'].value_counts(normalize=True).mul(100).round(2).reset_index()\n",
    "frequencia_streaming.columns = ['Streaming', 'Porcentagem']\n",
    "print(frequencia_streaming.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "\n",
    "# 3. Top 5 G√™neros por Contagem (Explorando as Colunas Dummies Wide)\n",
    "# Conta o total de '1' (presen√ßa do g√™nero) em cada coluna Genre_\n",
    "print(\"\\n[Distribui√ß√£o de Frequ√™ncia: Top 5 G√™neros Mais Frequentes]\")\n",
    "genre_cols = df_principal.filter(like='Genre_').columns\n",
    "contagem_generos = df_principal[genre_cols].sum().sort_values(ascending=False).reset_index()\n",
    "contagem_generos.columns = ['G√™nero', 'Contagem']\n",
    "contagem_generos['G√™nero'] = contagem_generos['G√™nero'].str.replace('Genre_', '')\n",
    "print(contagem_generos.head(5).to_markdown(numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c97cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos (Recomenda-se carregar df_principal aqui) ---\n",
    "imdb_data_dir = 'data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "\n",
    "# Carrega o DataFrame principal (assumindo que existe)\n",
    "try:\n",
    "    df_principal = pd.read_parquet(principal_parquet)\n",
    "except Exception:\n",
    "    # Se o carregamento falhar, assumimos que o usu√°rio ajustar√° o caminho.\n",
    "    # Para o prop√≥sito da resposta, o c√≥digo de visualiza√ß√£o √© fornecido.\n",
    "    pass\n",
    "\n",
    "# Configura√ß√£o de estilo visual\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# --- V1: Distribui√ß√£o da Nota M√©dia IMDb (Vari√°vel Alvo) ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_principal['imdb_rating_concatenada'].dropna(), kde=True, bins=30)\n",
    "plt.title('V1: Distribui√ß√£o da Nota M√©dia IMDb', fontsize=15)\n",
    "plt.xlabel('Nota IMDb')\n",
    "plt.ylabel('Frequ√™ncia')\n",
    "plt.show()\n",
    "\n",
    "# --- V2: Contagem de T√≠tulos Lan√ßados por D√©cada (Vari√°vel Temporal) ---\n",
    "# Filtrando anos razo√°veis (a partir de 1950)\n",
    "df_principal['release_decade'] = (df_principal['release_year'] // 10) * 10\n",
    "plt.figure(figsize=(12, 5))\n",
    "df_principal[df_principal['release_decade'] > 1950]['release_decade'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('V2: Contagem de T√≠tulos Lan√ßados por D√©cada', fontsize=15)\n",
    "plt.xlabel('D√©cada de Lan√ßamento')\n",
    "plt.ylabel('N√∫mero de T√≠tulos')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# --- V3: Distribui√ß√£o de T√≠tulos por Servi√ßo de Streaming (Vari√°vel Categ√≥rica) ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(y='streaming', data=df_principal, order=df_principal['streaming'].value_counts().index)\n",
    "plt.title('V3: Distribui√ß√£o de T√≠tulos por Servi√ßo de Streaming', fontsize=15)\n",
    "plt.xlabel('N√∫mero de T√≠tulos')\n",
    "plt.ylabel('Servi√ßo de Streaming')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eedeea9",
   "metadata": {},
   "source": [
    "### An√°lise Bivariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce47ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = 'data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "\n",
    "# 1. Carrega o DataFrame Principal\n",
    "try:\n",
    "    df_principal = pd.read_parquet(principal_parquet)\n",
    "except Exception as e:\n",
    "    print(f\"ERRO ao carregar o arquivo Parquet: {e}\")\n",
    "    print(\"Certifique-se de que o arquivo 'principal_tidy.parquet' foi gerado corretamente na etapa Tidy.\")\n",
    "    exit()\n",
    "\n",
    "# Remove Nulos na vari√°vel-alvo para an√°lises\n",
    "df_bivariada = df_principal.dropna(subset=['imdb_rating_concatenada']).copy()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# I. Rela√ß√£o entre SERVI√áO DE STREAMING e NOTA IMDb\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "print(\"### I. Streaming vs. IMDb Rating ###\")\n",
    "streaming_analise = df_bivariada.groupby('streaming')['imdb_rating_concatenada'].agg(\n",
    "    count='count',\n",
    "    media='mean',\n",
    "    mediana='median',\n",
    "    desvio_padrao='std',\n",
    "    min_rating='min',\n",
    "    max_rating='max'\n",
    ").sort_values(by='media', ascending=False).round(2)\n",
    "\n",
    "print(\"\\n[M√©tricas do IMDb Rating por Servi√ßo de Streaming]\")\n",
    "print(streaming_analise.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# II. Rela√ß√£o entre TIPO DE T√çTULO (Movie/TV Show) e NOTA IMDb\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n### II. Tipo de T√≠tulo vs. IMDb Rating ###\")\n",
    "type_analise = df_bivariada.groupby('type')['imdb_rating_concatenada'].agg(\n",
    "    count='count',\n",
    "    media='mean',\n",
    "    mediana='median',\n",
    "    desvio_padrao='std',\n",
    ").sort_values(by='media', ascending=False).round(2)\n",
    "\n",
    "print(\"\\n[M√©tricas do IMDb Rating por Tipo de T√≠tulo]\")\n",
    "print(type_analise.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# III. Rela√ß√£o entre TOP G√äNEROS e NOTA IMDb\n",
    "# (Usando as colunas Dummy para comparar a nota m√©dia dos t√≠tulos que possuem o g√™nero)\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n### III. Top G√™neros vs. IMDb Rating ###\")\n",
    "\n",
    "# Seleciona as colunas dummy de G√™nero\n",
    "genre_cols = df_bivariada.filter(like='Genre_').columns\n",
    "\n",
    "# Cria uma lista para armazenar os resultados\n",
    "genero_ratings = []\n",
    "\n",
    "# Analisa o rating m√©dio para os t√≠tulos que cont√™m cada g√™nero (onde Genre_X == 1)\n",
    "for col in genre_cols:\n",
    "    media = df_bivariada[df_bivariada[col] == 1]['imdb_rating_concatenada'].mean()\n",
    "    contagem = df_bivariada[df_bivariada[col] == 1].shape[0]\n",
    "    \n",
    "    if contagem >= 50: # Filtra g√™neros com poucas observa√ß√µes\n",
    "        genero_ratings.append({\n",
    "            'G√™nero': col.replace('Genre_', ''),\n",
    "            'M√©dia Rating': round(media, 2),\n",
    "            'Contagem': contagem\n",
    "        })\n",
    "\n",
    "df_genero_ratings = pd.DataFrame(genero_ratings).sort_values(by='M√©dia Rating', ascending=False)\n",
    "\n",
    "print(\"\\n[Top G√™neros por M√©dia de IMDb Rating (Contagem m√≠nima de 50)]\")\n",
    "print(df_genero_ratings.head(10).to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ff0de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = 'data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "\n",
    "# Carrega o DataFrame principal\n",
    "try:\n",
    "    df_principal = pd.read_parquet(principal_parquet)\n",
    "except Exception:\n",
    "    # Caso o carregamento falhe no ambiente, o usu√°rio ajustar√° o caminho\n",
    "    pass\n",
    "\n",
    "# DataFrame para an√°lise bivariada (sem nulos no alvo)\n",
    "df_bivariada = df_principal.dropna(subset=['imdb_rating_concatenada']).copy()\n",
    "\n",
    "# Configura√ß√£o de estilo visual\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# --- V4: Distribui√ß√£o da Nota IMDb por Servi√ßo de Streaming (Box Plot) ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='streaming', y='imdb_rating_concatenada', data=df_bivariada, palette=\"Set2\")\n",
    "plt.title('V4: Distribui√ß√£o da Nota IMDb por Servi√ßo de Streaming', fontsize=15)\n",
    "plt.xlabel('Servi√ßo de Streaming')\n",
    "plt.ylabel('Nota IMDb')\n",
    "plt.show()\n",
    "\n",
    "# --- V5: Distribui√ß√£o da Nota IMDb por Tipo de T√≠tulo (Box Plot) ---\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='type', y='imdb_rating_concatenada', data=df_bivariada, palette=\"viridis\")\n",
    "plt.title('V5: Distribui√ß√£o da Nota IMDb por Tipo de T√≠tulo', fontsize=15)\n",
    "plt.xlabel('Tipo de T√≠tulo')\n",
    "plt.ylabel('Nota IMDb')\n",
    "plt.show()\n",
    "\n",
    "# --- V6: Top 5 G√™neros vs. M√©dia de Nota IMDb (Bar Plot) ---\n",
    "\n",
    "# 1. Identifica os Top 5 G√™neros por Volume\n",
    "genre_cols = df_bivariada.filter(like='Genre_').columns\n",
    "top_genres_by_volume = df_bivariada[genre_cols].sum().sort_values(ascending=False).head(5).index.tolist()\n",
    "\n",
    "# 2. Calcula a M√©dia de Rating para cada Top G√™nero\n",
    "genre_mean_ratings = []\n",
    "for col in top_genres_by_volume:\n",
    "    mean_rating = df_bivariada[df_bivariada[col] == 1]['imdb_rating_concatenada'].mean()\n",
    "    genre_mean_ratings.append({\n",
    "        'G√™nero': col.replace('Genre_', ''),\n",
    "        'M√©dia Rating': mean_rating\n",
    "    })\n",
    "\n",
    "df_genre_ratings = pd.DataFrame(genre_mean_ratings).sort_values(by='M√©dia Rating', ascending=False)\n",
    "\n",
    "# 3. Plota o resultado\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='M√©dia Rating', y='G√™nero', data=df_genre_ratings, palette=\"coolwarm\")\n",
    "plt.title('V6: M√©dia de Nota IMDb pelos Top 5 G√™neros', fontsize=15)\n",
    "plt.xlabel('M√©dia de Nota IMDb')\n",
    "plt.ylabel('G√™nero')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae794bbe",
   "metadata": {},
   "source": [
    "### An√°lise Multivariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0895a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = 'data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "\n",
    "# 1. Carrega o DataFrame Principal\n",
    "try:\n",
    "    df_principal = pd.read_parquet(principal_parquet)\n",
    "except Exception as e:\n",
    "    print(f\"ERRO ao carregar o arquivo Parquet: {e}\")\n",
    "    print(\"Certifique-se de que o arquivo 'principal_tidy.parquet' foi gerado corretamente.\")\n",
    "    exit()\n",
    "\n",
    "# Remove Nulos na vari√°vel-alvo\n",
    "df_multi = df_principal.dropna(subset=['imdb_rating_concatenada']).copy()\n",
    "\n",
    "\n",
    "# 2. Seleciona as colunas para correla√ß√£o\n",
    "# Inclui a vari√°vel-alvo (IMDb Rating) e todas as colunas dummy de G√™nero/Pa√≠s\n",
    "correlation_cols = ['imdb_rating_concatenada']\n",
    "correlation_cols.extend(df_multi.filter(like='Genre_').columns.tolist())\n",
    "correlation_cols.extend(df_multi.filter(like='Country_').columns.tolist())\n",
    "\n",
    "df_corr = df_multi[correlation_cols]\n",
    "\n",
    "# 3. Calcula o Coeficiente de Correla√ß√£o de Pearson\n",
    "# A correla√ß√£o entre uma vari√°vel num√©rica e uma bin√°ria (0 ou 1) √© v√°lida.\n",
    "correlation_matrix = df_corr.corr()\n",
    "\n",
    "# 4. Extrai a correla√ß√£o da vari√°vel-alvo (imdb_rating_concatenada) com todas as outras\n",
    "imdb_correlations = correlation_matrix['imdb_rating_concatenada'].sort_values(ascending=False)\n",
    "\n",
    "# Remove a autocorrela√ß√£o (1.0)\n",
    "imdb_correlations = imdb_correlations.drop('imdb_rating_concatenada')\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 5. Exibe os Resultados (Top 10 Positivos e Negativos)\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "print(\"### Resultados da An√°lise Multivariada: Correla√ß√£o com IMDb Rating ###\")\n",
    "\n",
    "# Top 10 Correla√ß√µes Positivas (Features que mais aumentam o Rating)\n",
    "top_positive = imdb_correlations.head(10).reset_index()\n",
    "top_positive.columns = ['Feature', 'Correla√ß√£o']\n",
    "print(\"\\n[Top 10 Correla√ß√µes POSITIVAS (Maior Peso no Rating)]\")\n",
    "print(top_positive.to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "# Top 10 Correla√ß√µes Negativas (Features que mais diminuem o Rating)\n",
    "top_negative = imdb_correlations.tail(10).reset_index()\n",
    "top_negative.columns = ['Feature', 'Correla√ß√£o']\n",
    "print(\"\\n[Top 10 Correla√ß√µes NEGATIVAS (Menor Peso no Rating)]\")\n",
    "print(top_negative.to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4f859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = 'data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "\n",
    "# 1. Carrega o DataFrame principal e prepara para correla√ß√£o\n",
    "try:\n",
    "    df_principal = pd.read_parquet(principal_parquet)\n",
    "except Exception:\n",
    "    # Se o carregamento falhar, o usu√°rio ajustar√° o caminho.\n",
    "    pass\n",
    "\n",
    "df_multi = df_principal.dropna(subset=['imdb_rating_concatenada']).copy()\n",
    "\n",
    "# 2. Seleciona colunas e calcula a Correla√ß√£o de Pearson com o alvo\n",
    "correlation_cols = ['imdb_rating_concatenada']\n",
    "correlation_cols.extend(df_multi.filter(like='Genre_').columns.tolist())\n",
    "correlation_cols.extend(df_multi.filter(like='Country_').columns.tolist())\n",
    "df_corr = df_multi[correlation_cols]\n",
    "correlation_matrix = df_corr.corr()\n",
    "imdb_correlations = correlation_matrix['imdb_rating_concatenada'].drop('imdb_rating_concatenada').sort_values(ascending=False)\n",
    "\n",
    "# 3. Prepara dados para plotagem: Top 10 Positivos e Top 10 Negativos\n",
    "top_positive = imdb_correlations.head(10).reset_index()\n",
    "top_negative = imdb_correlations.tail(10).reset_index()\n",
    "df_top_corr = pd.concat([top_positive, top_negative])\n",
    "df_top_corr.columns = ['Feature', 'Correlation']\n",
    "\n",
    "# Limpa nomes das features para melhor visualiza√ß√£o\n",
    "df_top_corr['Feature'] = df_top_corr['Feature'].str.replace('Genre_', 'G√™nero: ').str.replace('Country_', 'Pa√≠s: ')\n",
    "df_top_corr = df_top_corr.sort_values(by='Correlation', ascending=False)\n",
    "\n",
    "# 4. Plotagem dos Top 20 features mais correlacionadas\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# CORRE√á√ÉO: Converte a Series de cores para uma LISTA de Python com .tolist()\n",
    "cores_personalizadas = df_top_corr['Correlation'].apply(lambda x: 'darkgreen' if x > 0 else 'darkred').tolist()\n",
    "\n",
    "sns.barplot(x='Correlation', y='Feature', data=df_top_corr, \n",
    "            palette=cores_personalizadas) # Usa a lista de cores corrigida\n",
    "\n",
    "plt.title('V7: Top 20 Correla√ß√µes (IMDb Rating vs. Pa√≠ses e G√™neros)', fontsize=16)\n",
    "plt.xlabel('Coeficiente de Correla√ß√£o de Pearson')\n",
    "plt.ylabel('Feature (G√™nero ou Pa√≠s)')\n",
    "plt.axvline(x=0, color='black', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b309d033",
   "metadata": {},
   "source": [
    "### Testes de Hip√≥tese\n",
    "‚Ä¢ H1: Filmes de terror costumam ter uma nota menor que a m√©dia\n",
    "\n",
    "‚Ä¢ H2: Filmes no Disney Plus chegam mais r√°pido ao streaming\n",
    "\n",
    "‚Ä¢ H3: Atores dedicados ao g√™nero de terror participam de menos produ√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b3fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = 'data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "actors_parquet = os.path.join(imdb_data_dir, 'actors_tidy.parquet')\n",
    "\n",
    "# Conecta ao DuckDB\n",
    "con = duckdb.connect(database=':memory:', read_only=False)\n",
    "\n",
    "# Fun√ß√£o para executar SQL, retornar DataFrame e imprimir o resultado\n",
    "def run_and_get_df(query_title, sql_query):\n",
    "    print(f\"\\n--- Resultados do Teste: {query_title} ---\")\n",
    "    try:\n",
    "        result = con.execute(sql_query).fetchdf()\n",
    "        print(result.to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO: Falha ao executar a pesquisa SQL. Motivo: {e}\")\n",
    "        print(\"Verifique se os arquivos Parquet foram gerados e o caminho est√° correto.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# H1: Filmes de terror costumam ter uma nota menor que a m√©dia\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_h1 = f\"\"\"\n",
    "SELECT \n",
    "    ROUND(AVG(imdb_rating_concatenada), 2) AS media_geral_imdb,\n",
    "    ROUND(AVG(CASE WHEN \"Genre_Horror\" = 1 THEN imdb_rating_concatenada ELSE NULL END), 2) AS media_horror_imdb\n",
    "FROM '{principal_parquet}'\n",
    "WHERE type = 'Movie';\n",
    "\"\"\"\n",
    "df_h1_raw = run_and_get_df(\"H1: Nota de Filmes de Terror vs. M√©dia Geral\", query_h1)\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# H2: Filmes no Disney Plus chegam mais r√°pido ao streaming\n",
    "# (Medido pela diferen√ßa de anos entre Lan√ßamento e Adi√ß√£o ao Streaming)\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_h2 = f\"\"\"\n",
    "WITH Time_to_Stream AS (\n",
    "    SELECT\n",
    "        streaming,\n",
    "        -- Extrai o ano do campo date_added e subtrai do release_year\n",
    "        (CAST(SUBSTR(date_added, 1, 4) AS INTEGER) - release_year) AS time_to_stream_years\n",
    "    FROM '{principal_parquet}'\n",
    "    WHERE date_added IS NOT NULL AND release_year IS NOT NULL AND type = 'Movie'\n",
    ")\n",
    "SELECT\n",
    "    streaming,\n",
    "    ROUND(AVG(time_to_stream_years), 2) AS media_tempo_adicao_anos\n",
    "FROM Time_to_Stream\n",
    "WHERE streaming IN ('Disney+', 'Netflix', 'Prime Video')\n",
    "GROUP BY streaming\n",
    "ORDER BY media_tempo_adicao_anos ASC;\n",
    "\"\"\"\n",
    "df_h2 = run_and_get_df(\"H2: Tempo M√©dio de Adi√ß√£o ao Streaming (Filmes)\", query_h2)\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# H3: Atores dedicados ao g√™nero de terror participam de menos produ√ß√µes \n",
    "# (M√©dia de Participa√ß√£o de Atores (Terror vs. Todos os Outros))\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_h3_modified = f\"\"\"\n",
    "WITH Actor_Participation AS (\n",
    "    SELECT\n",
    "        t2.actor_name,\n",
    "        COUNT(t1.show_id) AS total_participations,\n",
    "        -- Indica se o ator participou de algum t√≠tulo de Terror (MAX > 0 implica em True)\n",
    "        MAX(t1.\"Genre_Horror\") AS is_horror_actor\n",
    "    FROM '{principal_parquet}' AS t1\n",
    "    JOIN '{actors_parquet}' AS t2 ON t1.show_id = t2.show_id\n",
    "    WHERE t2.actor_name != 'Unknown' AND t1.type = 'Movie' -- Focando apenas em Filmes\n",
    "    GROUP BY t2.actor_name\n",
    ")\n",
    "SELECT\n",
    "    'Atores de Terror' AS grupo_ator,\n",
    "    ROUND(AVG(total_participations), 2) AS media_titulos_por_ator\n",
    "FROM Actor_Participation\n",
    "WHERE is_horror_actor = 1\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'Outros Atores (N√£o Terror)' AS grupo_ator,\n",
    "    ROUND(AVG(total_participations), 2) AS media_titulos_por_ator\n",
    "FROM Actor_Participation\n",
    "WHERE is_horror_actor = 0 -- Todos os atores que n√£o t√™m participa√ß√£o no g√™nero Horror.\n",
    "\"\"\"\n",
    "df_h3 = run_and_get_df(\"H3: M√©dia de Participa√ß√£o de Atores (Terror vs. Outros)\", query_h3_modified)\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6efafc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_h1_raw is not None:\n",
    "    df_h1 = df_h1_raw.melt(var_name='Categoria', value_name='M√©dia Rating')\n",
    "    df_h1['Categoria'] = df_h1['Categoria'].replace({\n",
    "        'media_geral': 'M√©dia Geral (Filmes)',\n",
    "        'media_horror': 'M√©dia Terror (Filmes)'\n",
    "    })\n",
    "    # Visualiza√ß√£o V8\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.barplot(x='Categoria', y='M√©dia Rating', data=df_h1, palette=['grey', 'red'])\n",
    "    plt.title('V8: M√©dia de Nota IMDb: Filmes de Terror vs. Geral (H1)', fontsize=14)\n",
    "    plt.ylabel('M√©dia de Nota IMDb')\n",
    "    plt.ylim(df_h1['M√©dia Rating'].min() - 0.2, df_h1['M√©dia Rating'].max() + 0.1) # Ajuste din√¢mico\n",
    "    plt.show()\n",
    "\n",
    "if df_h2 is not None:\n",
    "    df_h2 = df_h2.sort_values('media_tempo_adicao_anos', ascending=True)\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    sns.barplot(x='streaming', y='media_tempo_adicao_anos', data=df_h2, palette=\"muted\")\n",
    "    plt.title('V9: Tempo M√©dio (Anos) entre Lan√ßamento e Adi√ß√£o (H2)', fontsize=14)\n",
    "    plt.xlabel('Servi√ßo de Streaming')\n",
    "    plt.ylabel('Tempo M√©dio de Espera (Anos)')\n",
    "    plt.show()\n",
    "\n",
    "if df_h3 is not None:\n",
    "    df_h3 = df_h3.sort_values('media_titulos_por_ator', ascending=False)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x='grupo_ator', y='media_titulos_por_ator', data=df_h3, palette=['darkred', 'grey'])\n",
    "    plt.title('V10: M√©dia de T√≠tulos Participados por Ator (H3)', fontsize=14)\n",
    "    plt.xlabel('Grupo de Atores')\n",
    "    plt.ylabel('M√©dia de T√≠tulos por Ator')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
