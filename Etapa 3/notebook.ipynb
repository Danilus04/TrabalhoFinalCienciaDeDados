{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "114adf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necess√°rias\n",
    "import pandas as pd\n",
    "import os\n",
    "import kagglehub\n",
    "import shutil\n",
    "import requests\n",
    "import gzip\n",
    "import duckdb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b06efe",
   "metadata": {},
   "source": [
    "# Etapa 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0840c9",
   "metadata": {},
   "source": [
    "### Transforma√ß√£o Tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2673bdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14216 entries, 0 to 14215\n",
      "Data columns (total 79 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Unnamed: 0                  14216 non-null  int64  \n",
      " 1   show_id                     14216 non-null  object \n",
      " 2   type                        14216 non-null  object \n",
      " 3   title                       14216 non-null  object \n",
      " 4   director                    10644 non-null  object \n",
      " 5   cast                        13086 non-null  object \n",
      " 6   country                     7863 non-null   object \n",
      " 7   date_added                  7892 non-null   object \n",
      " 8   release_year                14216 non-null  int64  \n",
      " 9   rating                      14008 non-null  object \n",
      " 10  duration                    14216 non-null  object \n",
      " 11  listed_in                   14216 non-null  object \n",
      " 12  description                 14216 non-null  object \n",
      " 13  genres_processed            14216 non-null  object \n",
      " 14  streaming                   14216 non-null  object \n",
      " 15  imdb_rating_concatenada     14216 non-null  float64\n",
      " 16  Genre_Action                14216 non-null  int64  \n",
      " 17  Genre_Adventure             14216 non-null  int64  \n",
      " 18  Genre_Animals               14216 non-null  int64  \n",
      " 19  Genre_Animation             14216 non-null  int64  \n",
      " 20  Genre_Anime                 14216 non-null  int64  \n",
      " 21  Genre_Arthouse              14216 non-null  int64  \n",
      " 22  Genre_Arts                  14216 non-null  int64  \n",
      " 23  Genre_Biographical          14216 non-null  int64  \n",
      " 24  Genre_British TV            14216 non-null  int64  \n",
      " 25  Genre_Buddy                 14216 non-null  int64  \n",
      " 26  Genre_Classic               14216 non-null  int64  \n",
      " 27  Genre_Comedy                14216 non-null  int64  \n",
      " 28  Genre_Coming of Age         14216 non-null  int64  \n",
      " 29  Genre_Competition           14216 non-null  int64  \n",
      " 30  Genre_Concert Film          14216 non-null  int64  \n",
      " 31  Genre_Crime                 14216 non-null  int64  \n",
      " 32  Genre_Cult                  14216 non-null  int64  \n",
      " 33  Genre_Culture               14216 non-null  int64  \n",
      " 34  Genre_Dance                 14216 non-null  int64  \n",
      " 35  Genre_Disaster              14216 non-null  int64  \n",
      " 36  Genre_Documentary           14216 non-null  int64  \n",
      " 37  Genre_Drama                 14216 non-null  int64  \n",
      " 38  Genre_Entertainment         14216 non-null  int64  \n",
      " 39  Genre_Faith & Spirituality  14216 non-null  int64  \n",
      " 40  Genre_Family                14216 non-null  int64  \n",
      " 41  Genre_Fantasy               14216 non-null  int64  \n",
      " 42  Genre_Fitness               14216 non-null  int64  \n",
      " 43  Genre_Game Show             14216 non-null  int64  \n",
      " 44  Genre_Historical            14216 non-null  int64  \n",
      " 45  Genre_Horror                14216 non-null  int64  \n",
      " 46  Genre_Independent           14216 non-null  int64  \n",
      " 47  Genre_International         14216 non-null  int64  \n",
      " 48  Genre_Kids                  14216 non-null  int64  \n",
      " 49  Genre_Korean TV             14216 non-null  int64  \n",
      " 50  Genre_LGBTQ                 14216 non-null  int64  \n",
      " 51  Genre_Lifestyle             14216 non-null  int64  \n",
      " 52  Genre_Medical               14216 non-null  int64  \n",
      " 53  Genre_Military and War      14216 non-null  int64  \n",
      " 54  Genre_Music                 14216 non-null  int64  \n",
      " 55  Genre_Musical               14216 non-null  int64  \n",
      " 56  Genre_Mystery               14216 non-null  int64  \n",
      " 57  Genre_Nature                14216 non-null  int64  \n",
      " 58  Genre_Parody                14216 non-null  int64  \n",
      " 59  Genre_Reality               14216 non-null  int64  \n",
      " 60  Genre_Romance               14216 non-null  int64  \n",
      " 61  Genre_Sci-Fi                14216 non-null  int64  \n",
      " 62  Genre_Science               14216 non-null  int64  \n",
      " 63  Genre_Soap Opera            14216 non-null  int64  \n",
      " 64  Genre_Spanish TV            14216 non-null  int64  \n",
      " 65  Genre_Sports                14216 non-null  int64  \n",
      " 66  Genre_Spy/Espionage         14216 non-null  int64  \n",
      " 67  Genre_Stand-Up Comedy       14216 non-null  int64  \n",
      " 68  Genre_Superhero             14216 non-null  int64  \n",
      " 69  Genre_Survival              14216 non-null  int64  \n",
      " 70  Genre_Suspense              14216 non-null  int64  \n",
      " 71  Genre_Talk Show             14216 non-null  int64  \n",
      " 72  Genre_Teen                  14216 non-null  int64  \n",
      " 73  Genre_Thriller              14216 non-null  int64  \n",
      " 74  Genre_Travel                14216 non-null  int64  \n",
      " 75  Genre_Unknown               14216 non-null  int64  \n",
      " 76  Genre_Variety               14216 non-null  int64  \n",
      " 77  Genre_Western               14216 non-null  int64  \n",
      " 78  Genre_Young Adult           14216 non-null  int64  \n",
      "dtypes: float64(1), int64(65), object(13)\n",
      "memory usage: 8.6+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14216 entries, 0 to 14215\n",
      "Columns: 142 entries, Unnamed: 0 to Genre_Young Adult\n",
      "dtypes: float64(1), int64(128), object(13)\n",
      "memory usage: 15.4+ MB\n"
     ]
    }
   ],
   "source": [
    "imdb_data_dir = '../data'\n",
    "output_csv_file = os.path.join(imdb_data_dir, 'filmes_series_imdb.csv')\n",
    "df_streaming = pd.read_csv(output_csv_file)\n",
    "df_streaming.info()\n",
    "\n",
    "output_csv_file = os.path.join(imdb_data_dir, 'filmes_series_imdb.csv')\n",
    "df_streaming_completo = pd.read_csv(output_csv_file)\n",
    "\n",
    "#Dividir generos em varios booleanos\n",
    "df_streaming_completo['genres_processed'] = df_streaming_completo['genres_processed'].fillna('Unknown')\n",
    "genre_dummies = df_streaming_completo['genres_processed'].str.get_dummies(sep=', ')\n",
    "genre_dummies = genre_dummies.add_prefix('Genre_')\n",
    "df_streaming_completo = pd.concat([df_streaming_completo, genre_dummies], axis=1)\n",
    "df_streaming_completo.to_csv(output_csv_file)\n",
    "\n",
    "df_streaming_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fad9548c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7863 entries, 2 to 14213\n",
      "Columns: 143 entries, Unnamed: 0.1 to Genre_Young Adult.1\n",
      "dtypes: float64(1), int64(129), object(13)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "def remover_nulos_por_coluna(caminho_csv, nomes_colunas):\n",
    "    \"\"\"\n",
    "    L√™ um arquivo CSV e retorna um DataFrame sem as linhas\n",
    "    onde a 'nomes_colunas' especificada est√° em branco (NaN ou string vazia).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. L√™ o arquivo CSV\n",
    "        df = pd.read_csv(caminho_csv)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERRO: O arquivo '{caminho_csv}' n√£o foi encontrado.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao ler o arquivo: {e}\")\n",
    "        return None\n",
    "\n",
    "    # 2. Verifica se a coluna existe no DataFrame\n",
    "    colunas_faltando = [col for col in nomes_colunas if col not in df.columns]\n",
    "    \n",
    "    if colunas_faltando:\n",
    "        print(f\"ERRO: As seguintes colunas n√£o foram encontradas: {colunas_faltando}\")\n",
    "        print(f\"Colunas dispon√≠veis: {df.columns.to_list()}\")\n",
    "        return None\n",
    "\n",
    "    # 3. Remove as linhas onde a coluna √© Nula (NaN, pd.NA, etc.)\n",
    "    df_limpo = df.dropna(subset=nomes_colunas)\n",
    "\n",
    "    # 5. Devolve o DataFrame limpo\n",
    "    return df_limpo\n",
    "\n",
    "#Teste\n",
    "df = remover_nulos_por_coluna(output_csv_file, ['country'])\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6355e83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando processamento da coluna 'country' no arquivo: ../data\\filmes_series_imdb.csv\n",
      "Criando colunas dummy para Pa√≠ses...\n",
      "Total de colunas ap√≥s adi√ß√£o dos Pa√≠ses: 269\n",
      "‚úÖ Arquivo CSV atualizado com sucesso. Total de colunas Country_: 126\n"
     ]
    }
   ],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = '../data'\n",
    "output_csv_file = os.path.join(imdb_data_dir, 'filmes_series_imdb.csv')\n",
    "\n",
    "print(f\"Iniciando processamento da coluna 'country' no arquivo: {output_csv_file}\")\n",
    "\n",
    "# 1. Carrega o DataFrame base\n",
    "try:\n",
    "    df_base = pd.read_csv(output_csv_file)\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: Arquivo '{output_csv_file}' n√£o encontrado. Verifique a conclus√£o das etapas anteriores.\")\n",
    "    exit()\n",
    "\n",
    "# 2. Pr√©-processamento: Trata valores nulos na coluna 'country'\n",
    "# Preenche NaN para que o get_dummies funcione\n",
    "df_base['country'] = df_base['country'].fillna('Unknown Country')\n",
    "\n",
    "# 3. Cria Dummies: Separa os pa√≠ses e cria colunas booleanas\n",
    "print(\"Criando colunas dummy para Pa√≠ses...\")\n",
    "country_dummies = df_base['country'].str.get_dummies(sep=', ')\n",
    "country_dummies = country_dummies.add_prefix('Country_')\n",
    "\n",
    "# 4. Concatena as Dummies de Pa√≠s com o DataFrame\n",
    "df_base = pd.concat([df_base, country_dummies], axis=1)\n",
    "print(f\"Total de colunas ap√≥s adi√ß√£o dos Pa√≠ses: {df_base.shape[1]}\")\n",
    "\n",
    "# 5. Salva o DataFrame ATUALIZADO (sobrescrevendo o arquivo CSV)\n",
    "df_base.to_csv(output_csv_file, index=False)\n",
    "\n",
    "print(f\"‚úÖ Arquivo CSV atualizado com sucesso. Total de colunas Country_: {country_dummies.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b03fb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tabela de Atores (Long) criada: 92446 linhas.\n",
      "‚úÖ Tabela de Diretores (Long) criada: 14821 linhas.\n",
      "‚úÖ Tabela Principal Tidy (Wide) criada: 8812 linhas, 265 colunas.\n",
      "\n",
      "üì¶ Exportando tabelas Tidy para o formato Parquet...\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müì¶ Exportando tabelas Tidy para o formato Parquet...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Tabela 1: Principal (Wide)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[43mdf_principal_tidy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimdb_data_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprincipal_tidy.parquet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m   - principal_tidy.parquet (Tabela Principal com Pa√≠ses/G√™neros Wide)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Tabela 2: Diretores (Long)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\Estudos\\Codigos\\CienciaDeDados\\ReposotorioDoGit\\TrabalhoFinal\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\Estudos\\Codigos\\CienciaDeDados\\ReposotorioDoGit\\TrabalhoFinal\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:3124\u001b[39m, in \u001b[36mDataFrame.to_parquet\u001b[39m\u001b[34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[39m\n\u001b[32m   3043\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3044\u001b[39m \u001b[33;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[32m   3045\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3120\u001b[39m \u001b[33;03m>>> content = f.read()\u001b[39;00m\n\u001b[32m   3121\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3122\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparquet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[32m-> \u001b[39m\u001b[32m3124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3125\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3132\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3133\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\Estudos\\Codigos\\CienciaDeDados\\ReposotorioDoGit\\TrabalhoFinal\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:478\u001b[39m, in \u001b[36mto_parquet\u001b[39m\u001b[34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(partition_cols, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    477\u001b[39m     partition_cols = [partition_cols]\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m impl = \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m path_or_buf: FilePath | WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] = io.BytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[32m    482\u001b[39m impl.write(\n\u001b[32m    483\u001b[39m     df,\n\u001b[32m    484\u001b[39m     path_or_buf,\n\u001b[32m   (...)\u001b[39m\u001b[32m    490\u001b[39m     **kwargs,\n\u001b[32m    491\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\Estudos\\Codigos\\CienciaDeDados\\ReposotorioDoGit\\TrabalhoFinal\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:68\u001b[39m, in \u001b[36mget_engine\u001b[39m\u001b[34m(engine)\u001b[39m\n\u001b[32m     65\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     66\u001b[39m             error_msgs += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m - \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(err)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     69\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnable to find a usable engine; \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtried using: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfastparquet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     71\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA suitable version of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     72\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msupport.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTrying to import the above resulted in these errors:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     75\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     76\u001b[39m     )\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[31mImportError\u001b[39m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = '../data'\n",
    "output_csv_file = os.path.join(imdb_data_dir, 'filmes_series_imdb.csv')\n",
    "\n",
    "# 1. Carrega o DataFrame base (agora com as colunas Country_ adicionadas pelo script anterior)\n",
    "try:\n",
    "    df_base = pd.read_csv(output_csv_file)\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: Arquivo '{output_csv_file}' n√£o encontrado. Verifique a execu√ß√£o do script de country.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. NORMALIZA√á√ÉO: Cria Tabelas Long (Alta Cardinalidade)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# --- A. Tabela de Elenco (Cast) Tidy (Formato Long) ---\n",
    "# Trata Nulos e explode\n",
    "df_cast = df_base[['show_id', 'cast']].copy()\n",
    "df_cast['cast'] = df_cast['cast'].fillna('Unknown') \n",
    "df_cast['cast_list'] = df_cast['cast'].str.split(', ')\n",
    "df_actors_tidy = df_cast.explode('cast_list').rename(columns={'cast_list': 'actor_name'})\n",
    "df_actors_tidy = df_actors_tidy[['show_id', 'actor_name']].drop_duplicates()\n",
    "print(f\"‚úÖ Tabela de Atores (Long) criada: {df_actors_tidy.shape[0]} linhas.\")\n",
    "\n",
    "\n",
    "# --- B. Tabela de Diretores (Director) Tidy (Formato Long) ---\n",
    "# Trata Nulos e explode\n",
    "df_director = df_base[['show_id', 'director']].copy()\n",
    "df_director['director'] = df_director['director'].fillna('Unknown')\n",
    "df_director['director_list'] = df_director['director'].str.split(', ')\n",
    "df_directors_tidy = df_director.explode('director_list').rename(columns={'director_list': 'director_name'})\n",
    "df_directors_tidy = df_directors_tidy[['show_id', 'director_name']].drop_duplicates()\n",
    "print(f\"‚úÖ Tabela de Diretores (Long) criada: {df_directors_tidy.shape[0]} linhas.\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. CRIA√á√ÉO DA TABELA PRINCIPAL Tidy (Wide)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# Colunas a SEREM REMOVIDAS da Tabela Principal Tidy:\n",
    "# 'cast', 'director', 'country' s√£o agora redundantes ou foram normalizadas\n",
    "columns_to_drop = [\n",
    "    'cast', 'director', 'country', 'listed_in' # 'listed_in' √© substitu√≠do por 'genres_processed'\n",
    "]\n",
    "\n",
    "# Usa .copy() para evitar SettingWithCopyWarning\n",
    "df_principal_tidy = df_base.drop(columns=columns_to_drop, errors='ignore').copy()\n",
    "\n",
    "# Remove a coluna tempor√°ria 'genres_processed' se preferir usar apenas as Dummies de G√™nero\n",
    "# df_principal_tidy = df_principal_tidy.drop(columns=['genres_processed'], errors='ignore')\n",
    "\n",
    "# Remove duplicatas baseadas no show_id (caso tenham entrado duplicatas na leitura do CSV)\n",
    "df_principal_tidy = df_principal_tidy.drop_duplicates(subset=['show_id']).reset_index(drop=True)\n",
    "print(f\"‚úÖ Tabela Principal Tidy (Wide) criada: {df_principal_tidy.shape[0]} linhas, {df_principal_tidy.shape[1]} colunas.\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 4. EXPORTA√á√ÉO PARA PARQUET\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "print(\"\\nüì¶ Exportando tabelas Tidy para o formato Parquet...\")\n",
    "\n",
    "# Tabela 1: Principal (Wide)\n",
    "df_principal_tidy.to_parquet(os.path.join(imdb_data_dir, 'principal_tidy.parquet'), index=False)\n",
    "print(\"   - principal_tidy.parquet (Tabela Principal com Pa√≠ses/G√™neros Wide)\")\n",
    "\n",
    "# Tabela 2: Diretores (Long)\n",
    "df_directors_tidy.to_parquet(os.path.join(imdb_data_dir, 'directors_tidy.parquet'), index=False)\n",
    "print(\"   - directors_tidy.parquet (Tabela de Diretores Long)\")\n",
    "\n",
    "# Tabela 3: Atores (Long)\n",
    "df_actors_tidy.to_parquet(os.path.join(imdb_data_dir, 'actors_tidy.parquet'), index=False)\n",
    "print(\"   - actors_tidy.parquet (Tabela de Atores Long)\")\n",
    "\n",
    "print(\"\\nüéâ Etapa Tidy Data conclu√≠da com sucesso. Seu projeto est√° pronto para as Consultas SQL!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93476d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data_dir = '../data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "directors_parquet = os.path.join(imdb_data_dir, 'directors_tidy.parquet')\n",
    "actors_parquet = os.path.join(imdb_data_dir, 'actors_tidy.parquet')\n",
    "output_csv_file = os.path.join(imdb_data_dir, 'principal_tidy.csv')\n",
    "\n",
    "try:\n",
    "    # 1. Carrega o arquivo Parquet Principal (Tabela Wide)\n",
    "    print(\"Carregando Tabela Principal (Parquet)...\")\n",
    "    df_principal = pd.read_parquet(principal_parquet)\n",
    "\n",
    "    # 2. Salva a Tabela Principal no formato CSV\n",
    "    df_principal.to_csv(output_csv_file, index=False)\n",
    "    print(f\"‚úÖ Tabela principal salva como CSV: {output_csv_file}\")\n",
    "    \n",
    "    # 3. Exibe um preview do DataFrame principal\n",
    "    print(\"\\n--- Preview da Tabela Principal Tidy (CSV) ---\")\n",
    "    print(df_principal.head())\n",
    "\n",
    "    # 4. Exibe um preview da Tabela de Diretores (Long)\n",
    "    print(\"\\n--- Preview da Tabela de Diretores Tidy ---\")\n",
    "    df_directors = pd.read_parquet(directors_parquet)\n",
    "    print(df_directors.head())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nERRO: Falha ao encontrar o arquivo. O Parquet precisa ser gerado primeiro. {e}\")\n",
    "    print(\"\\nPor favor, execute o c√≥digo da etapa Tidy anterior ('C√≥digo da Etapa Tidy Principal Atualizado') para gerar os arquivos Parquet, e depois execute este c√≥digo de visualiza√ß√£o.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db71162",
   "metadata": {},
   "source": [
    "### Consultas SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa6bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define o diret√≥rio e os nomes dos arquivos Parquet\n",
    "imdb_data_dir = '../data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "directors_parquet = os.path.join(imdb_data_dir, 'directors_tidy.parquet')\n",
    "actors_parquet = os.path.join(imdb_data_dir, 'actors_tidy.parquet')\n",
    "\n",
    "# 2. Conecta ao DuckDB\n",
    "con = duckdb.connect(database=':memory:', read_only=False)\n",
    "\n",
    "# Fun√ß√£o auxiliar para executar e formatar a sa√≠da\n",
    "def run_query(query_title, sql_query):\n",
    "    print(f\"\\n--- Consulta: {query_title} ---\")\n",
    "    try:\n",
    "        result = con.execute(sql_query).fetchdf()\n",
    "        print(result.to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao executar a consulta: {e}\")\n",
    "        print(\"Verifique se os nomes das colunas e arquivos Parquet est√£o corretos.\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# üéØ 1. Agrega√ß√£o e Compara√ß√£o: M√©dia de Nota por Servi√ßo de Streaming\n",
    "# (An√°lise Bivariada: streaming vs. imdb_rating_concatenada)\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_1 = f\"\"\"\n",
    "SELECT\n",
    "    streaming,\n",
    "    COUNT(show_id) AS total_titulos,\n",
    "    ROUND(AVG(imdb_rating_concatenada), 2) AS media_imdb_rating\n",
    "FROM '{principal_parquet}'\n",
    "GROUP BY 1\n",
    "ORDER BY media_imdb_rating DESC;\n",
    "\"\"\"\n",
    "run_query(\"1. Ranking de M√©dia de Nota por Streaming\", query_1)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# üéØ 2. Tend√™ncia Temporal: N√∫mero de T√≠tulos Lan√ßados por D√©cada\n",
    "# (An√°lise Temporal e de Distribui√ß√£o)\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_2 = f\"\"\"\n",
    "SELECT\n",
    "    (FLOOR(release_year / 10) * 10) AS decada_lancamento,\n",
    "    COUNT(show_id) AS total_titulos\n",
    "FROM '{principal_parquet}'\n",
    "WHERE release_year IS NOT NULL AND release_year >= 1950\n",
    "GROUP BY 1\n",
    "ORDER BY 1;\n",
    "\"\"\"\n",
    "run_query(\"2. Tend√™ncia de Lan√ßamento por D√©cada\", query_2)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# üéØ 3. Ranking com Agrega√ß√£o Complexa: Top 10 Diretores com Mais T√≠tulos e M√©dia de Nota\n",
    "# (Requer JOIN entre as tabelas Long e Wide)\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_3 = f\"\"\"\n",
    "WITH Director_Stats AS (\n",
    "    SELECT\n",
    "        t2.director_name,\n",
    "        COUNT(t1.show_id) AS num_titulos,\n",
    "        ROUND(AVG(t1.imdb_rating_concatenada), 2) AS media_rating\n",
    "    FROM '{principal_parquet}' AS t1\n",
    "    JOIN '{directors_parquet}' AS t2 ON t1.show_id = t2.show_id\n",
    "    WHERE t2.director_name != 'Unknown' AND t1.imdb_rating_concatenada IS NOT NULL\n",
    "    GROUP BY 1\n",
    ")\n",
    "SELECT\n",
    "    *,\n",
    "    RANK() OVER (ORDER BY num_titulos DESC) AS ranking_volume\n",
    "FROM Director_Stats\n",
    "WHERE num_titulos >= 5 -- Filtro para diretores relevantes\n",
    "ORDER BY num_titulos DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "run_query(\"3. Top 10 Diretores (Volume e M√©dia de Nota)\", query_3)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# üéØ 4. Correla√ß√£o: M√©dia de Nota IMDb por G√™nero\n",
    "# (An√°lise de correla√ß√£o usando colunas Wide/Dummy)\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_4 = f\"\"\"\n",
    "SELECT\n",
    "    'Documentary' AS genero,\n",
    "    ROUND(AVG(CASE WHEN \"Genre_Documentary\" = 1 THEN imdb_rating_concatenada ELSE NULL END), 2) AS media_rating\n",
    "FROM '{principal_parquet}'\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'Drama' AS genero,\n",
    "    ROUND(AVG(CASE WHEN \"Genre_Drama\" = 1 THEN imdb_rating_concatenada ELSE NULL END), 2) AS media_rating\n",
    "FROM '{principal_parquet}'\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'Kids' AS genero,\n",
    "    ROUND(AVG(CASE WHEN \"Genre_Kids\" = 1 THEN imdb_rating_concatenada ELSE NULL END), 2) AS media_rating\n",
    "FROM '{principal_parquet}'\n",
    "ORDER BY media_rating DESC;\n",
    "\"\"\"\n",
    "run_query(\"4. M√©dia de Nota dos G√™neros (Documentary, Drama, Kids)\", query_4)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# üéØ 5. An√°lise Bivariada: Pa√≠ses com Maior Nota M√©dia no IMDB\n",
    "# (Usa as colunas Country_ Dummy para agregar)\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_5 = f\"\"\"\n",
    "SELECT\n",
    "    'United States' AS country,\n",
    "    ROUND(AVG(CASE WHEN \"Country_United States\" = 1 THEN imdb_rating_concatenada ELSE NULL END), 2) AS media_rating\n",
    "FROM '{principal_parquet}'\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'India' AS country,\n",
    "    ROUND(AVG(CASE WHEN \"Country_India\" = 1 THEN imdb_rating_concatenada ELSE NULL END), 2) AS media_rating\n",
    "FROM '{principal_parquet}'\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'United Kingdom' AS country,\n",
    "    ROUND(AVG(CASE WHEN \"Country_United Kingdom\" = 1 THEN imdb_rating_concatenada ELSE NULL END), 2) AS media_rating\n",
    "FROM '{principal_parquet}'\n",
    "ORDER BY media_rating DESC;\n",
    "\"\"\"\n",
    "run_query(\"5. M√©dia de Nota dos 3 Principais Pa√≠ses de Origem\", query_5)\n",
    "\n",
    "# Fecha a conex√£o com o DuckDB\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5edf6cf",
   "metadata": {},
   "source": [
    "### An√°lise Univariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da74b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = '../data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "\n",
    "# 1. Carrega o DataFrame Principal\n",
    "try:\n",
    "    df_principal = pd.read_parquet(principal_parquet)\n",
    "except Exception as e:\n",
    "    print(f\"ERRO ao carregar o arquivo Parquet: {e}\")\n",
    "    print(\"Certifique-se de que o arquivo 'principal_tidy.parquet' foi gerado corretamente.\")\n",
    "    exit()\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# I. AN√ÅLISE DE VARI√ÅVEIS NUM√âRICAS (Medidas de Tend√™ncia Central e Dispers√£o)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "print(\"### I. An√°lise de Vari√°veis Num√©ricas (IMDb Rating e Ano de Lan√ßamento) ###\")\n",
    "\n",
    "# 1. Vari√°veis a serem analisadas\n",
    "numeric_cols = ['imdb_rating_concatenada', 'release_year']\n",
    "\n",
    "# 2. Gera√ß√£o da tabela de estat√≠sticas descritivas\n",
    "stats_descritivas = df_principal[numeric_cols].describe().T\n",
    "\n",
    "# Adiciona o c√°lculo da Moda (Mode)\n",
    "for col in numeric_cols:\n",
    "    stats_descritivas.loc[col, 'mode'] = df_principal[col].mode()[0]\n",
    "\n",
    "# Exibe o resultado formatado\n",
    "print(\"\\n[Medidas de Tend√™ncia Central e Dispers√£o]\")\n",
    "print(stats_descritivas[['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'mode']].to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# II. AN√ÅLISE DE VARI√ÅVEIS CATEG√ìRICAS (Distribui√ß√£o de Frequ√™ncia)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "print(\"\\n### II. An√°lise de Vari√°veis Categ√≥ricas (Distribui√ß√£o de Frequ√™ncia) ###\")\n",
    "\n",
    "# 1. Distribui√ß√£o de Frequ√™ncia: Tipo de T√≠tulo (Movie/TV Show)\n",
    "print(\"\\n[Distribui√ß√£o de Frequ√™ncia: Tipo de T√≠tulo]\")\n",
    "frequencia_type = df_principal['type'].value_counts(normalize=True).mul(100).round(2).reset_index()\n",
    "frequencia_type.columns = ['Tipo', 'Porcentagem']\n",
    "print(frequencia_type.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "\n",
    "# 2. Distribui√ß√£o de Frequ√™ncia: Servi√ßo de Streaming\n",
    "print(\"\\n[Distribui√ß√£o de Frequ√™ncia: Servi√ßo de Streaming]\")\n",
    "frequencia_streaming = df_principal['streaming'].value_counts(normalize=True).mul(100).round(2).reset_index()\n",
    "frequencia_streaming.columns = ['Streaming', 'Porcentagem']\n",
    "print(frequencia_streaming.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "\n",
    "# 3. Top 5 G√™neros por Contagem (Explorando as Colunas Dummies Wide)\n",
    "# Conta o total de '1' (presen√ßa do g√™nero) em cada coluna Genre_\n",
    "print(\"\\n[Distribui√ß√£o de Frequ√™ncia: Top 5 G√™neros Mais Frequentes]\")\n",
    "genre_cols = df_principal.filter(like='Genre_').columns\n",
    "contagem_generos = df_principal[genre_cols].sum().sort_values(ascending=False).reset_index()\n",
    "contagem_generos.columns = ['G√™nero', 'Contagem']\n",
    "contagem_generos['G√™nero'] = contagem_generos['G√™nero'].str.replace('Genre_', '')\n",
    "print(contagem_generos.head(5).to_markdown(numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c97cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos (Recomenda-se carregar df_principal aqui) ---\n",
    "imdb_data_dir = '../data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "\n",
    "# Carrega o DataFrame principal (assumindo que existe)\n",
    "try:\n",
    "    df_principal = pd.read_parquet(principal_parquet)\n",
    "except Exception:\n",
    "    # Se o carregamento falhar, assumimos que o usu√°rio ajustar√° o caminho.\n",
    "    # Para o prop√≥sito da resposta, o c√≥digo de visualiza√ß√£o √© fornecido.\n",
    "    pass\n",
    "\n",
    "# Configura√ß√£o de estilo visual\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# --- V1: Distribui√ß√£o da Nota M√©dia IMDb (Vari√°vel Alvo) ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_principal['imdb_rating_concatenada'].dropna(), kde=True, bins=30)\n",
    "plt.title('V1: Distribui√ß√£o da Nota M√©dia IMDb', fontsize=15)\n",
    "plt.xlabel('Nota IMDb')\n",
    "plt.ylabel('Frequ√™ncia')\n",
    "plt.show()\n",
    "\n",
    "# --- V2: Contagem de T√≠tulos Lan√ßados por D√©cada (Vari√°vel Temporal) ---\n",
    "# Filtrando anos razo√°veis (a partir de 1950)\n",
    "df_principal['release_decade'] = (df_principal['release_year'] // 10) * 10\n",
    "plt.figure(figsize=(12, 5))\n",
    "df_principal[df_principal['release_decade'] > 1950]['release_decade'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('V2: Contagem de T√≠tulos Lan√ßados por D√©cada', fontsize=15)\n",
    "plt.xlabel('D√©cada de Lan√ßamento')\n",
    "plt.ylabel('N√∫mero de T√≠tulos')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# --- V3: Distribui√ß√£o de T√≠tulos por Servi√ßo de Streaming (Vari√°vel Categ√≥rica) ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(y='streaming', data=df_principal, order=df_principal['streaming'].value_counts().index)\n",
    "plt.title('V3: Distribui√ß√£o de T√≠tulos por Servi√ßo de Streaming', fontsize=15)\n",
    "plt.xlabel('N√∫mero de T√≠tulos')\n",
    "plt.ylabel('Servi√ßo de Streaming')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eedeea9",
   "metadata": {},
   "source": [
    "### An√°lise Bivariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce47ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = '../data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "\n",
    "# 1. Carrega o DataFrame Principal\n",
    "try:\n",
    "    df_principal = pd.read_parquet(principal_parquet)\n",
    "except Exception as e:\n",
    "    print(f\"ERRO ao carregar o arquivo Parquet: {e}\")\n",
    "    print(\"Certifique-se de que o arquivo 'principal_tidy.parquet' foi gerado corretamente na etapa Tidy.\")\n",
    "    exit()\n",
    "\n",
    "# Remove Nulos na vari√°vel-alvo para an√°lises\n",
    "df_bivariada = df_principal.dropna(subset=['imdb_rating_concatenada']).copy()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# I. Rela√ß√£o entre SERVI√áO DE STREAMING e NOTA IMDb\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "print(\"### I. Streaming vs. IMDb Rating ###\")\n",
    "streaming_analise = df_bivariada.groupby('streaming')['imdb_rating_concatenada'].agg(\n",
    "    count='count',\n",
    "    media='mean',\n",
    "    mediana='median',\n",
    "    desvio_padrao='std',\n",
    "    min_rating='min',\n",
    "    max_rating='max'\n",
    ").sort_values(by='media', ascending=False).round(2)\n",
    "\n",
    "print(\"\\n[M√©tricas do IMDb Rating por Servi√ßo de Streaming]\")\n",
    "print(streaming_analise.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# II. Rela√ß√£o entre TIPO DE T√çTULO (Movie/TV Show) e NOTA IMDb\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n### II. Tipo de T√≠tulo vs. IMDb Rating ###\")\n",
    "type_analise = df_bivariada.groupby('type')['imdb_rating_concatenada'].agg(\n",
    "    count='count',\n",
    "    media='mean',\n",
    "    mediana='median',\n",
    "    desvio_padrao='std',\n",
    ").sort_values(by='media', ascending=False).round(2)\n",
    "\n",
    "print(\"\\n[M√©tricas do IMDb Rating por Tipo de T√≠tulo]\")\n",
    "print(type_analise.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# III. Rela√ß√£o entre TOP G√äNEROS e NOTA IMDb\n",
    "# (Usando as colunas Dummy para comparar a nota m√©dia dos t√≠tulos que possuem o g√™nero)\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n### III. Top G√™neros vs. IMDb Rating ###\")\n",
    "\n",
    "# Seleciona as colunas dummy de G√™nero\n",
    "genre_cols = df_bivariada.filter(like='Genre_').columns\n",
    "\n",
    "# Cria uma lista para armazenar os resultados\n",
    "genero_ratings = []\n",
    "\n",
    "# Analisa o rating m√©dio para os t√≠tulos que cont√™m cada g√™nero (onde Genre_X == 1)\n",
    "for col in genre_cols:\n",
    "    media = df_bivariada[df_bivariada[col] == 1]['imdb_rating_concatenada'].mean()\n",
    "    contagem = df_bivariada[df_bivariada[col] == 1].shape[0]\n",
    "    \n",
    "    if contagem >= 50: # Filtra g√™neros com poucas observa√ß√µes\n",
    "        genero_ratings.append({\n",
    "            'G√™nero': col.replace('Genre_', ''),\n",
    "            'M√©dia Rating': round(media, 2),\n",
    "            'Contagem': contagem\n",
    "        })\n",
    "\n",
    "df_genero_ratings = pd.DataFrame(genero_ratings).sort_values(by='M√©dia Rating', ascending=False)\n",
    "\n",
    "print(\"\\n[Top G√™neros por M√©dia de IMDb Rating (Contagem m√≠nima de 50)]\")\n",
    "print(df_genero_ratings.head(10).to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ff0de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = '../data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "\n",
    "# Carrega o DataFrame principal\n",
    "try:\n",
    "    df_principal = pd.read_parquet(principal_parquet)\n",
    "except Exception:\n",
    "    # Caso o carregamento falhe no ambiente, o usu√°rio ajustar√° o caminho\n",
    "    pass\n",
    "\n",
    "# DataFrame para an√°lise bivariada (sem nulos no alvo)\n",
    "df_bivariada = df_principal.dropna(subset=['imdb_rating_concatenada']).copy()\n",
    "\n",
    "# Configura√ß√£o de estilo visual\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# --- V4: Distribui√ß√£o da Nota IMDb por Servi√ßo de Streaming (Box Plot) ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='streaming', y='imdb_rating_concatenada', data=df_bivariada, palette=\"Set2\")\n",
    "plt.title('V4: Distribui√ß√£o da Nota IMDb por Servi√ßo de Streaming', fontsize=15)\n",
    "plt.xlabel('Servi√ßo de Streaming')\n",
    "plt.ylabel('Nota IMDb')\n",
    "plt.show()\n",
    "\n",
    "# --- V5: Distribui√ß√£o da Nota IMDb por Tipo de T√≠tulo (Box Plot) ---\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='type', y='imdb_rating_concatenada', data=df_bivariada, palette=\"viridis\")\n",
    "plt.title('V5: Distribui√ß√£o da Nota IMDb por Tipo de T√≠tulo', fontsize=15)\n",
    "plt.xlabel('Tipo de T√≠tulo')\n",
    "plt.ylabel('Nota IMDb')\n",
    "plt.show()\n",
    "\n",
    "# --- V6: Top 5 G√™neros vs. M√©dia de Nota IMDb (Bar Plot) ---\n",
    "\n",
    "# 1. Identifica os Top 5 G√™neros por Volume\n",
    "genre_cols = df_bivariada.filter(like='Genre_').columns\n",
    "top_genres_by_volume = df_bivariada[genre_cols].sum().sort_values(ascending=False).head(5).index.tolist()\n",
    "\n",
    "# 2. Calcula a M√©dia de Rating para cada Top G√™nero\n",
    "genre_mean_ratings = []\n",
    "for col in top_genres_by_volume:\n",
    "    mean_rating = df_bivariada[df_bivariada[col] == 1]['imdb_rating_concatenada'].mean()\n",
    "    genre_mean_ratings.append({\n",
    "        'G√™nero': col.replace('Genre_', ''),\n",
    "        'M√©dia Rating': mean_rating\n",
    "    })\n",
    "\n",
    "df_genre_ratings = pd.DataFrame(genre_mean_ratings).sort_values(by='M√©dia Rating', ascending=False)\n",
    "\n",
    "# 3. Plota o resultado\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='M√©dia Rating', y='G√™nero', data=df_genre_ratings, palette=\"coolwarm\")\n",
    "plt.title('V6: M√©dia de Nota IMDb pelos Top 5 G√™neros', fontsize=15)\n",
    "plt.xlabel('M√©dia de Nota IMDb')\n",
    "plt.ylabel('G√™nero')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae794bbe",
   "metadata": {},
   "source": [
    "### An√°lise Multivariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0895a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = '../data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "\n",
    "# 1. Carrega o DataFrame Principal\n",
    "try:\n",
    "    df_principal = pd.read_parquet(principal_parquet)\n",
    "except Exception as e:\n",
    "    print(f\"ERRO ao carregar o arquivo Parquet: {e}\")\n",
    "    print(\"Certifique-se de que o arquivo 'principal_tidy.parquet' foi gerado corretamente.\")\n",
    "    exit()\n",
    "\n",
    "# Remove Nulos na vari√°vel-alvo\n",
    "df_multi = df_principal.dropna(subset=['imdb_rating_concatenada']).copy()\n",
    "\n",
    "\n",
    "# 2. Seleciona as colunas para correla√ß√£o\n",
    "# Inclui a vari√°vel-alvo (IMDb Rating) e todas as colunas dummy de G√™nero/Pa√≠s\n",
    "correlation_cols = ['imdb_rating_concatenada']\n",
    "correlation_cols.extend(df_multi.filter(like='Genre_').columns.tolist())\n",
    "correlation_cols.extend(df_multi.filter(like='Country_').columns.tolist())\n",
    "\n",
    "df_corr = df_multi[correlation_cols]\n",
    "\n",
    "# 3. Calcula o Coeficiente de Correla√ß√£o de Pearson\n",
    "# A correla√ß√£o entre uma vari√°vel num√©rica e uma bin√°ria (0 ou 1) √© v√°lida.\n",
    "correlation_matrix = df_corr.corr()\n",
    "\n",
    "# 4. Extrai a correla√ß√£o da vari√°vel-alvo (imdb_rating_concatenada) com todas as outras\n",
    "imdb_correlations = correlation_matrix['imdb_rating_concatenada'].sort_values(ascending=False)\n",
    "\n",
    "# Remove a autocorrela√ß√£o (1.0)\n",
    "imdb_correlations = imdb_correlations.drop('imdb_rating_concatenada')\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 5. Exibe os Resultados (Top 10 Positivos e Negativos)\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "print(\"### Resultados da An√°lise Multivariada: Correla√ß√£o com IMDb Rating ###\")\n",
    "\n",
    "# Top 10 Correla√ß√µes Positivas (Features que mais aumentam o Rating)\n",
    "top_positive = imdb_correlations.head(10).reset_index()\n",
    "top_positive.columns = ['Feature', 'Correla√ß√£o']\n",
    "print(\"\\n[Top 10 Correla√ß√µes POSITIVAS (Maior Peso no Rating)]\")\n",
    "print(top_positive.to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "# Top 10 Correla√ß√µes Negativas (Features que mais diminuem o Rating)\n",
    "top_negative = imdb_correlations.tail(10).reset_index()\n",
    "top_negative.columns = ['Feature', 'Correla√ß√£o']\n",
    "print(\"\\n[Top 10 Correla√ß√µes NEGATIVAS (Menor Peso no Rating)]\")\n",
    "print(top_negative.to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4f859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = '../data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "\n",
    "# 1. Carrega o DataFrame principal e prepara para correla√ß√£o\n",
    "try:\n",
    "    df_principal = pd.read_parquet(principal_parquet)\n",
    "except Exception:\n",
    "    # Se o carregamento falhar, o usu√°rio ajustar√° o caminho.\n",
    "    pass\n",
    "\n",
    "df_multi = df_principal.dropna(subset=['imdb_rating_concatenada']).copy()\n",
    "\n",
    "# 2. Seleciona colunas e calcula a Correla√ß√£o de Pearson com o alvo\n",
    "correlation_cols = ['imdb_rating_concatenada']\n",
    "correlation_cols.extend(df_multi.filter(like='Genre_').columns.tolist())\n",
    "correlation_cols.extend(df_multi.filter(like='Country_').columns.tolist())\n",
    "df_corr = df_multi[correlation_cols]\n",
    "correlation_matrix = df_corr.corr()\n",
    "imdb_correlations = correlation_matrix['imdb_rating_concatenada'].drop('imdb_rating_concatenada').sort_values(ascending=False)\n",
    "\n",
    "# 3. Prepara dados para plotagem: Top 10 Positivos e Top 10 Negativos\n",
    "top_positive = imdb_correlations.head(10).reset_index()\n",
    "top_negative = imdb_correlations.tail(10).reset_index()\n",
    "df_top_corr = pd.concat([top_positive, top_negative])\n",
    "df_top_corr.columns = ['Feature', 'Correlation']\n",
    "\n",
    "# Limpa nomes das features para melhor visualiza√ß√£o\n",
    "df_top_corr['Feature'] = df_top_corr['Feature'].str.replace('Genre_', 'G√™nero: ').str.replace('Country_', 'Pa√≠s: ')\n",
    "df_top_corr = df_top_corr.sort_values(by='Correlation', ascending=False)\n",
    "\n",
    "# 4. Plotagem dos Top 20 features mais correlacionadas\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# CORRE√á√ÉO: Converte a Series de cores para uma LISTA de Python com .tolist()\n",
    "cores_personalizadas = df_top_corr['Correlation'].apply(lambda x: 'darkgreen' if x > 0 else 'darkred').tolist()\n",
    "\n",
    "sns.barplot(x='Correlation', y='Feature', data=df_top_corr, \n",
    "            palette=cores_personalizadas) # Usa a lista de cores corrigida\n",
    "\n",
    "plt.title('V7: Top 20 Correla√ß√µes (IMDb Rating vs. Pa√≠ses e G√™neros)', fontsize=16)\n",
    "plt.xlabel('Coeficiente de Correla√ß√£o de Pearson')\n",
    "plt.ylabel('Feature (G√™nero ou Pa√≠s)')\n",
    "plt.axvline(x=0, color='black', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b309d033",
   "metadata": {},
   "source": [
    "### Testes de Hip√≥tese\n",
    "‚Ä¢ H1: Filmes de terror costumam ter uma nota menor que a m√©dia\n",
    "\n",
    "‚Ä¢ H2: Filmes no Disney Plus chegam mais r√°pido ao streaming\n",
    "\n",
    "‚Ä¢ H3: Atores dedicados ao g√™nero de terror participam de menos produ√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b3fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = '../data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "actors_parquet = os.path.join(imdb_data_dir, 'actors_tidy.parquet')\n",
    "\n",
    "# Conecta ao DuckDB\n",
    "con = duckdb.connect(database=':memory:', read_only=False)\n",
    "\n",
    "# Fun√ß√£o para executar SQL, retornar DataFrame e imprimir o resultado\n",
    "def run_and_get_df(query_title, sql_query):\n",
    "    print(f\"\\n--- Resultados do Teste: {query_title} ---\")\n",
    "    try:\n",
    "        result = con.execute(sql_query).fetchdf()\n",
    "        print(result.to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO: Falha ao executar a pesquisa SQL. Motivo: {e}\")\n",
    "        print(\"Verifique se os arquivos Parquet foram gerados e o caminho est√° correto.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# H1: Filmes de terror costumam ter uma nota menor que a m√©dia\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_h1 = f\"\"\"\n",
    "SELECT \n",
    "    ROUND(AVG(imdb_rating_concatenada), 2) AS media_geral_imdb,\n",
    "    ROUND(AVG(CASE WHEN \"Genre_Horror\" = 1 THEN imdb_rating_concatenada ELSE NULL END), 2) AS media_horror_imdb\n",
    "FROM '{principal_parquet}'\n",
    "WHERE type = 'Movie';\n",
    "\"\"\"\n",
    "df_h1_raw = run_and_get_df(\"H1: Nota de Filmes de Terror vs. M√©dia Geral\", query_h1)\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# H2: Filmes no Disney Plus chegam mais r√°pido ao streaming\n",
    "# (Medido pela diferen√ßa de anos entre Lan√ßamento e Adi√ß√£o ao Streaming)\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_h2 = f\"\"\"\n",
    "WITH Time_to_Stream AS (\n",
    "    SELECT\n",
    "        streaming,\n",
    "        -- Extrai o ano do campo date_added e subtrai do release_year\n",
    "        (CAST(SUBSTR(date_added, 1, 4) AS INTEGER) - release_year) AS time_to_stream_years\n",
    "    FROM '{principal_parquet}'\n",
    "    WHERE date_added IS NOT NULL AND release_year IS NOT NULL AND type = 'Movie'\n",
    ")\n",
    "SELECT\n",
    "    streaming,\n",
    "    ROUND(AVG(time_to_stream_years), 2) AS media_tempo_adicao_anos\n",
    "FROM Time_to_Stream\n",
    "WHERE streaming IN ('Disney+', 'Netflix', 'Prime Video')\n",
    "GROUP BY streaming\n",
    "ORDER BY media_tempo_adicao_anos ASC;\n",
    "\"\"\"\n",
    "df_h2 = run_and_get_df(\"H2: Tempo M√©dio de Adi√ß√£o ao Streaming (Filmes)\", query_h2)\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# H3: Atores dedicados ao g√™nero de terror participam de menos produ√ß√µes \n",
    "# (M√©dia de Participa√ß√£o de Atores (Terror vs. Todos os Outros))\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_h3_modified = f\"\"\"\n",
    "WITH Actor_Participation AS (\n",
    "    SELECT\n",
    "        t2.actor_name,\n",
    "        COUNT(t1.show_id) AS total_participations,\n",
    "        -- Indica se o ator participou de algum t√≠tulo de Terror (MAX > 0 implica em True)\n",
    "        MAX(t1.\"Genre_Horror\") AS is_horror_actor\n",
    "    FROM '{principal_parquet}' AS t1\n",
    "    JOIN '{actors_parquet}' AS t2 ON t1.show_id = t2.show_id\n",
    "    WHERE t2.actor_name != 'Unknown' AND t1.type = 'Movie' -- Focando apenas em Filmes\n",
    "    GROUP BY t2.actor_name\n",
    ")\n",
    "SELECT\n",
    "    'Atores de Terror' AS grupo_ator,\n",
    "    ROUND(AVG(total_participations), 2) AS media_titulos_por_ator\n",
    "FROM Actor_Participation\n",
    "WHERE is_horror_actor = 1\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'Outros Atores (N√£o Terror)' AS grupo_ator,\n",
    "    ROUND(AVG(total_participations), 2) AS media_titulos_por_ator\n",
    "FROM Actor_Participation\n",
    "WHERE is_horror_actor = 0 -- Todos os atores que n√£o t√™m participa√ß√£o no g√™nero Horror.\n",
    "\"\"\"\n",
    "df_h3 = run_and_get_df(\"H3: M√©dia de Participa√ß√£o de Atores (Terror vs. Outros)\", query_h3_modified)\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6efafc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_h1_raw is not None:\n",
    "    df_h1 = df_h1_raw.melt(var_name='Categoria', value_name='M√©dia Rating')\n",
    "    df_h1['Categoria'] = df_h1['Categoria'].replace({\n",
    "        'media_geral': 'M√©dia Geral (Filmes)',\n",
    "        'media_horror': 'M√©dia Terror (Filmes)'\n",
    "    })\n",
    "    # Visualiza√ß√£o V8\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.barplot(x='Categoria', y='M√©dia Rating', data=df_h1, palette=['grey', 'red'])\n",
    "    plt.title('V8: M√©dia de Nota IMDb: Filmes de Terror vs. Geral (H1)', fontsize=14)\n",
    "    plt.ylabel('M√©dia de Nota IMDb')\n",
    "    plt.ylim(df_h1['M√©dia Rating'].min() - 0.2, df_h1['M√©dia Rating'].max() + 0.1) # Ajuste din√¢mico\n",
    "    plt.show()\n",
    "\n",
    "if df_h2 is not None:\n",
    "    df_h2 = df_h2.sort_values('media_tempo_adicao_anos', ascending=True)\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    sns.barplot(x='streaming', y='media_tempo_adicao_anos', data=df_h2, palette=\"muted\")\n",
    "    plt.title('V9: Tempo M√©dio (Anos) entre Lan√ßamento e Adi√ß√£o (H2)', fontsize=14)\n",
    "    plt.xlabel('Servi√ßo de Streaming')\n",
    "    plt.ylabel('Tempo M√©dio de Espera (Anos)')\n",
    "    plt.show()\n",
    "\n",
    "if df_h3 is not None:\n",
    "    df_h3 = df_h3.sort_values('media_titulos_por_ator', ascending=False)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x='grupo_ator', y='media_titulos_por_ator', data=df_h3, palette=['darkred', 'grey'])\n",
    "    plt.title('V10: M√©dia de T√≠tulos Participados por Ator (H3)', fontsize=14)\n",
    "    plt.xlabel('Grupo de Atores')\n",
    "    plt.ylabel('M√©dia de T√≠tulos por Ator')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
