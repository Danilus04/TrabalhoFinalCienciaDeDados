{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114adf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necess√°rias\n",
    "import pandas as pd\n",
    "import os\n",
    "import kagglehub\n",
    "import shutil\n",
    "import requests\n",
    "import gzip\n",
    "import duckdb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b06efe",
   "metadata": {},
   "source": [
    "# Etapa 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0840c9",
   "metadata": {},
   "source": [
    "### Transforma√ß√£o Tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2673bdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data_dir = '../data'\n",
    "output_csv_file = os.path.join(imdb_data_dir, 'filmes_series_imdb.csv')\n",
    "df_streaming = pd.read_csv(output_csv_file)\n",
    "df_streaming.info()\n",
    "\n",
    "output_csv_file = os.path.join(imdb_data_dir, 'filmes_series_imdb.csv')\n",
    "df_streaming_completo = pd.read_csv(output_csv_file)\n",
    "\n",
    "#Dividir generos em varios booleanos\n",
    "df_streaming_completo['genres_processed'] = df_streaming_completo['genres_processed'].fillna('Unknown')\n",
    "genre_dummies = df_streaming_completo['genres_processed'].str.get_dummies(sep=', ')\n",
    "genre_dummies = genre_dummies.add_prefix('Genre_')\n",
    "df_streaming_completo = pd.concat([df_streaming_completo, genre_dummies], axis=1)\n",
    "df_streaming_completo.to_csv(output_csv_file)\n",
    "\n",
    "df_streaming_completo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad9548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover_nulos_por_coluna(caminho_csv, nomes_colunas):\n",
    "    \"\"\"\n",
    "    L√™ um arquivo CSV e retorna um DataFrame sem as linhas\n",
    "    onde a 'nomes_colunas' especificada est√° em branco (NaN ou string vazia).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. L√™ o arquivo CSV\n",
    "        df = pd.read_csv(caminho_csv)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERRO: O arquivo '{caminho_csv}' n√£o foi encontrado.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao ler o arquivo: {e}\")\n",
    "        return None\n",
    "\n",
    "    # 2. Verifica se a coluna existe no DataFrame\n",
    "    colunas_faltando = [col for col in nomes_colunas if col not in df.columns]\n",
    "    \n",
    "    if colunas_faltando:\n",
    "        print(f\"ERRO: As seguintes colunas n√£o foram encontradas: {colunas_faltando}\")\n",
    "        print(f\"Colunas dispon√≠veis: {df.columns.to_list()}\")\n",
    "        return None\n",
    "\n",
    "    # 3. Remove as linhas onde a coluna √© Nula (NaN, pd.NA, etc.)\n",
    "    df_limpo = df.dropna(subset=nomes_colunas)\n",
    "\n",
    "    # 5. Devolve o DataFrame limpo\n",
    "    return df_limpo\n",
    "\n",
    "#Teste\n",
    "df = remover_nulos_por_coluna(output_csv_file, ['country'])\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6355e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = '../data'\n",
    "output_csv_file = os.path.join(imdb_data_dir, 'filmes_series_imdb.csv')\n",
    "\n",
    "print(f\"Iniciando processamento da coluna 'country' no arquivo: {output_csv_file}\")\n",
    "\n",
    "# 1. Carrega o DataFrame base\n",
    "try:\n",
    "    df_base = pd.read_csv(output_csv_file)\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: Arquivo '{output_csv_file}' n√£o encontrado. Verifique a conclus√£o das etapas anteriores.\")\n",
    "    exit()\n",
    "\n",
    "# 2. Pr√©-processamento: Trata valores nulos na coluna 'country'\n",
    "# Preenche NaN para que o get_dummies funcione\n",
    "df_base['country'] = df_base['country'].fillna('Unknown Country')\n",
    "\n",
    "# 3. Cria Dummies: Separa os pa√≠ses e cria colunas booleanas\n",
    "print(\"Criando colunas dummy para Pa√≠ses...\")\n",
    "country_dummies = df_base['country'].str.get_dummies(sep=', ')\n",
    "country_dummies = country_dummies.add_prefix('Country_')\n",
    "\n",
    "# 4. Concatena as Dummies de Pa√≠s com o DataFrame\n",
    "df_base = pd.concat([df_base, country_dummies], axis=1)\n",
    "print(f\"Total de colunas ap√≥s adi√ß√£o dos Pa√≠ses: {df_base.shape[1]}\")\n",
    "\n",
    "# 5. Salva o DataFrame ATUALIZADO (sobrescrevendo o arquivo CSV)\n",
    "df_base.to_csv(output_csv_file, index=False)\n",
    "\n",
    "print(f\"‚úÖ Arquivo CSV atualizado com sucesso. Total de colunas Country_: {country_dummies.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b03fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = '../data'\n",
    "output_csv_file = os.path.join(imdb_data_dir, 'filmes_series_imdb.csv')\n",
    "\n",
    "# 1. Carrega o DataFrame base (agora com as colunas Country_ adicionadas pelo script anterior)\n",
    "try:\n",
    "    df_base = pd.read_csv(output_csv_file)\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: Arquivo '{output_csv_file}' n√£o encontrado. Verifique a execu√ß√£o do script de country.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. NORMALIZA√á√ÉO: Cria Tabelas Long (Alta Cardinalidade)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# --- A. Tabela de Elenco (Cast) Tidy (Formato Long) ---\n",
    "# Trata Nulos e explode\n",
    "df_cast = df_base[['show_id', 'cast']].copy()\n",
    "df_cast['cast'] = df_cast['cast'].fillna('Unknown') \n",
    "df_cast['cast_list'] = df_cast['cast'].str.split(', ')\n",
    "df_actors_tidy = df_cast.explode('cast_list').rename(columns={'cast_list': 'actor_name'})\n",
    "df_actors_tidy = df_actors_tidy[['show_id', 'actor_name']].drop_duplicates()\n",
    "print(f\"‚úÖ Tabela de Atores (Long) criada: {df_actors_tidy.shape[0]} linhas.\")\n",
    "\n",
    "\n",
    "# --- B. Tabela de Diretores (Director) Tidy (Formato Long) ---\n",
    "# Trata Nulos e explode\n",
    "df_director = df_base[['show_id', 'director']].copy()\n",
    "df_director['director'] = df_director['director'].fillna('Unknown')\n",
    "df_director['director_list'] = df_director['director'].str.split(', ')\n",
    "df_directors_tidy = df_director.explode('director_list').rename(columns={'director_list': 'director_name'})\n",
    "df_directors_tidy = df_directors_tidy[['show_id', 'director_name']].drop_duplicates()\n",
    "print(f\"‚úÖ Tabela de Diretores (Long) criada: {df_directors_tidy.shape[0]} linhas.\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. CRIA√á√ÉO DA TABELA PRINCIPAL Tidy (Wide)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# Colunas a SEREM REMOVIDAS da Tabela Principal Tidy:\n",
    "# 'cast', 'director', 'country' s√£o agora redundantes ou foram normalizadas\n",
    "columns_to_drop = [\n",
    "    'cast', 'director', 'country', 'listed_in' # 'listed_in' √© substitu√≠do por 'genres_processed'\n",
    "]\n",
    "\n",
    "# Usa .copy() para evitar SettingWithCopyWarning\n",
    "df_principal_tidy = df_base.drop(columns=columns_to_drop, errors='ignore').copy()\n",
    "\n",
    "# Remove a coluna tempor√°ria 'genres_processed' se preferir usar apenas as Dummies de G√™nero\n",
    "# df_principal_tidy = df_principal_tidy.drop(columns=['genres_processed'], errors='ignore')\n",
    "\n",
    "# Remove duplicatas baseadas no show_id (caso tenham entrado duplicatas na leitura do CSV)\n",
    "df_principal_tidy = df_principal_tidy.drop_duplicates(subset=['show_id']).reset_index(drop=True)\n",
    "print(f\"‚úÖ Tabela Principal Tidy (Wide) criada: {df_principal_tidy.shape[0]} linhas, {df_principal_tidy.shape[1]} colunas.\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 4. EXPORTA√á√ÉO PARA PARQUET\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "print(\"\\nüì¶ Exportando tabelas Tidy para o formato Parquet...\")\n",
    "\n",
    "# Tabela 1: Principal (Wide)\n",
    "df_principal_tidy.to_parquet(os.path.join(imdb_data_dir, 'principal_tidy.parquet'), index=False)\n",
    "print(\"   - principal_tidy.parquet (Tabela Principal com Pa√≠ses/G√™neros Wide)\")\n",
    "\n",
    "# Tabela 2: Diretores (Long)\n",
    "df_directors_tidy.to_parquet(os.path.join(imdb_data_dir, 'directors_tidy.parquet'), index=False)\n",
    "print(\"   - directors_tidy.parquet (Tabela de Diretores Long)\")\n",
    "\n",
    "# Tabela 3: Atores (Long)\n",
    "df_actors_tidy.to_parquet(os.path.join(imdb_data_dir, 'actors_tidy.parquet'), index=False)\n",
    "print(\"   - actors_tidy.parquet (Tabela de Atores Long)\")\n",
    "\n",
    "print(\"\\nüéâ Etapa Tidy Data conclu√≠da com sucesso. Seu projeto est√° pronto para as Consultas SQL!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93476d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data_dir = '../data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "directors_parquet = os.path.join(imdb_data_dir, 'directors_tidy.parquet')\n",
    "actors_parquet = os.path.join(imdb_data_dir, 'actors_tidy.parquet')\n",
    "output_csv_file = os.path.join(imdb_data_dir, 'principal_tidy.csv')\n",
    "\n",
    "try:\n",
    "    # 1. Carrega o arquivo Parquet Principal (Tabela Wide)\n",
    "    print(\"Carregando Tabela Principal (Parquet)...\")\n",
    "    df_principal = pd.read_parquet(principal_parquet)\n",
    "\n",
    "    # 2. Salva a Tabela Principal no formato CSV\n",
    "    df_principal.to_csv(output_csv_file, index=False)\n",
    "    print(f\"‚úÖ Tabela principal salva como CSV: {output_csv_file}\")\n",
    "    \n",
    "    # 3. Exibe um preview do DataFrame principal\n",
    "    print(\"\\n--- Preview da Tabela Principal Tidy (CSV) ---\")\n",
    "    print(df_principal.head())\n",
    "\n",
    "    # 4. Exibe um preview da Tabela de Diretores (Long)\n",
    "    print(\"\\n--- Preview da Tabela de Diretores Tidy ---\")\n",
    "    df_directors = pd.read_parquet(directors_parquet)\n",
    "    print(df_directors.head())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nERRO: Falha ao encontrar o arquivo. O Parquet precisa ser gerado primeiro. {e}\")\n",
    "    print(\"\\nPor favor, execute o c√≥digo da etapa Tidy anterior ('C√≥digo da Etapa Tidy Principal Atualizado') para gerar os arquivos Parquet, e depois execute este c√≥digo de visualiza√ß√£o.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db71162",
   "metadata": {},
   "source": [
    "### Consultas SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa6bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define o diret√≥rio e os nomes dos arquivos Parquet\n",
    "imdb_data_dir = '../data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "directors_parquet = os.path.join(imdb_data_dir, 'directors_tidy.parquet')\n",
    "actors_parquet = os.path.join(imdb_data_dir, 'actors_tidy.parquet')\n",
    "\n",
    "# 2. Conecta ao DuckDB\n",
    "con = duckdb.connect(database=':memory:', read_only=False)\n",
    "\n",
    "# Fun√ß√£o auxiliar para executar e formatar a sa√≠da\n",
    "def run_query(query_title, sql_query):\n",
    "    print(f\"\\n--- Consulta: {query_title} ---\")\n",
    "    try:\n",
    "        result = con.execute(sql_query).fetchdf()\n",
    "        print(result.to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao executar a consulta: {e}\")\n",
    "        print(\"Verifique se os nomes das colunas e arquivos Parquet est√£o corretos.\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# üéØ 1. Agrega√ß√£o e Compara√ß√£o: M√©dia de Nota por Servi√ßo de Streaming\n",
    "# (An√°lise Bivariada: streaming vs. imdb_rating_concatenada)\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_1 = f\"\"\"\n",
    "SELECT\n",
    "    streaming,\n",
    "    COUNT(show_id) AS total_titulos,\n",
    "    ROUND(AVG(imdb_rating_concatenada), 2) AS media_imdb_rating\n",
    "FROM '{principal_parquet}'\n",
    "GROUP BY 1\n",
    "ORDER BY media_imdb_rating DESC;\n",
    "\"\"\"\n",
    "run_query(\"1. Ranking de M√©dia de Nota por Streaming\", query_1)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# üéØ 2. Tend√™ncia Temporal: N√∫mero de T√≠tulos Lan√ßados por D√©cada\n",
    "# (An√°lise Temporal e de Distribui√ß√£o)\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_2 = f\"\"\"\n",
    "SELECT\n",
    "    (FLOOR(release_year / 10) * 10) AS decada_lancamento,\n",
    "    COUNT(show_id) AS total_titulos\n",
    "FROM '{principal_parquet}'\n",
    "WHERE release_year IS NOT NULL AND release_year >= 1950\n",
    "GROUP BY 1\n",
    "ORDER BY 1;\n",
    "\"\"\"\n",
    "run_query(\"2. Tend√™ncia de Lan√ßamento por D√©cada\", query_2)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# üéØ 3. Ranking com Agrega√ß√£o Complexa: Top 10 Diretores com Mais T√≠tulos e M√©dia de Nota\n",
    "# (Requer JOIN entre as tabelas Long e Wide)\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_3 = f\"\"\"\n",
    "WITH Director_Stats AS (\n",
    "    SELECT\n",
    "        t2.director_name,\n",
    "        COUNT(t1.show_id) AS num_titulos,\n",
    "        ROUND(AVG(t1.imdb_rating_concatenada), 2) AS media_rating\n",
    "    FROM '{principal_parquet}' AS t1\n",
    "    JOIN '{directors_parquet}' AS t2 ON t1.show_id = t2.show_id\n",
    "    WHERE t2.director_name != 'Unknown' AND t1.imdb_rating_concatenada IS NOT NULL\n",
    "    GROUP BY 1\n",
    ")\n",
    "SELECT\n",
    "    *,\n",
    "    RANK() OVER (ORDER BY num_titulos DESC) AS ranking_volume\n",
    "FROM Director_Stats\n",
    "WHERE num_titulos >= 5 -- Filtro para diretores relevantes\n",
    "ORDER BY num_titulos DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "run_query(\"3. Top 10 Diretores (Volume e M√©dia de Nota)\", query_3)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# üéØ 4. Correla√ß√£o: M√©dia de Nota IMDb por G√™nero\n",
    "# (An√°lise de correla√ß√£o usando colunas Wide/Dummy)\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_4 = f\"\"\"\n",
    "SELECT\n",
    "    'Documentary' AS genero,\n",
    "    ROUND(AVG(CASE WHEN \"Genre_Documentary\" = 1 THEN imdb_rating_concatenada ELSE NULL END), 2) AS media_rating\n",
    "FROM '{principal_parquet}'\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'Drama' AS genero,\n",
    "    ROUND(AVG(CASE WHEN \"Genre_Drama\" = 1 THEN imdb_rating_concatenada ELSE NULL END), 2) AS media_rating\n",
    "FROM '{principal_parquet}'\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'Kids' AS genero,\n",
    "    ROUND(AVG(CASE WHEN \"Genre_Kids\" = 1 THEN imdb_rating_concatenada ELSE NULL END), 2) AS media_rating\n",
    "FROM '{principal_parquet}'\n",
    "ORDER BY media_rating DESC;\n",
    "\"\"\"\n",
    "run_query(\"4. M√©dia de Nota dos G√™neros (Documentary, Drama, Kids)\", query_4)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# üéØ 5. An√°lise Bivariada: Pa√≠ses com Maior Nota M√©dia no IMDB\n",
    "# (Usa as colunas Country_ Dummy para agregar)\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_5 = f\"\"\"\n",
    "SELECT\n",
    "    'United States' AS country,\n",
    "    ROUND(AVG(CASE WHEN \"Country_United States\" = 1 THEN imdb_rating_concatenada ELSE NULL END), 2) AS media_rating\n",
    "FROM '{principal_parquet}'\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'India' AS country,\n",
    "    ROUND(AVG(CASE WHEN \"Country_India\" = 1 THEN imdb_rating_concatenada ELSE NULL END), 2) AS media_rating\n",
    "FROM '{principal_parquet}'\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'United Kingdom' AS country,\n",
    "    ROUND(AVG(CASE WHEN \"Country_United Kingdom\" = 1 THEN imdb_rating_concatenada ELSE NULL END), 2) AS media_rating\n",
    "FROM '{principal_parquet}'\n",
    "ORDER BY media_rating DESC;\n",
    "\"\"\"\n",
    "run_query(\"5. M√©dia de Nota dos 3 Principais Pa√≠ses de Origem\", query_5)\n",
    "\n",
    "# Fecha a conex√£o com o DuckDB\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5edf6cf",
   "metadata": {},
   "source": [
    "### An√°lise Univariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da74b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = '../data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "\n",
    "# 1. Carrega o DataFrame Principal\n",
    "try:\n",
    "    df_principal = pd.read_parquet(principal_parquet)\n",
    "except Exception as e:\n",
    "    print(f\"ERRO ao carregar o arquivo Parquet: {e}\")\n",
    "    print(\"Certifique-se de que o arquivo 'principal_tidy.parquet' foi gerado corretamente.\")\n",
    "    exit()\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# I. AN√ÅLISE DE VARI√ÅVEIS NUM√âRICAS (Medidas de Tend√™ncia Central e Dispers√£o)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "print(\"### I. An√°lise de Vari√°veis Num√©ricas (IMDb Rating e Ano de Lan√ßamento) ###\")\n",
    "\n",
    "# 1. Vari√°veis a serem analisadas\n",
    "numeric_cols = ['imdb_rating_concatenada', 'release_year']\n",
    "\n",
    "# 2. Gera√ß√£o da tabela de estat√≠sticas descritivas\n",
    "stats_descritivas = df_principal[numeric_cols].describe().T\n",
    "\n",
    "# Adiciona o c√°lculo da Moda (Mode)\n",
    "for col in numeric_cols:\n",
    "    stats_descritivas.loc[col, 'mode'] = df_principal[col].mode()[0]\n",
    "\n",
    "# Exibe o resultado formatado\n",
    "print(\"\\n[Medidas de Tend√™ncia Central e Dispers√£o]\")\n",
    "print(stats_descritivas[['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'mode']].to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# II. AN√ÅLISE DE VARI√ÅVEIS CATEG√ìRICAS (Distribui√ß√£o de Frequ√™ncia)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "print(\"\\n### II. An√°lise de Vari√°veis Categ√≥ricas (Distribui√ß√£o de Frequ√™ncia) ###\")\n",
    "\n",
    "# 1. Distribui√ß√£o de Frequ√™ncia: Tipo de T√≠tulo (Movie/TV Show)\n",
    "print(\"\\n[Distribui√ß√£o de Frequ√™ncia: Tipo de T√≠tulo]\")\n",
    "frequencia_type = df_principal['type'].value_counts(normalize=True).mul(100).round(2).reset_index()\n",
    "frequencia_type.columns = ['Tipo', 'Porcentagem']\n",
    "print(frequencia_type.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "\n",
    "# 2. Distribui√ß√£o de Frequ√™ncia: Servi√ßo de Streaming\n",
    "print(\"\\n[Distribui√ß√£o de Frequ√™ncia: Servi√ßo de Streaming]\")\n",
    "frequencia_streaming = df_principal['streaming'].value_counts(normalize=True).mul(100).round(2).reset_index()\n",
    "frequencia_streaming.columns = ['Streaming', 'Porcentagem']\n",
    "print(frequencia_streaming.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "\n",
    "# 3. Top 5 G√™neros por Contagem (Explorando as Colunas Dummies Wide)\n",
    "# Conta o total de '1' (presen√ßa do g√™nero) em cada coluna Genre_\n",
    "print(\"\\n[Distribui√ß√£o de Frequ√™ncia: Top 5 G√™neros Mais Frequentes]\")\n",
    "genre_cols = df_principal.filter(like='Genre_').columns\n",
    "contagem_generos = df_principal[genre_cols].sum().sort_values(ascending=False).reset_index()\n",
    "contagem_generos.columns = ['G√™nero', 'Contagem']\n",
    "contagem_generos['G√™nero'] = contagem_generos['G√™nero'].str.replace('Genre_', '')\n",
    "print(contagem_generos.head(5).to_markdown(numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c97cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos (Recomenda-se carregar df_principal aqui) ---\n",
    "imdb_data_dir = '../data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "\n",
    "# Carrega o DataFrame principal (assumindo que existe)\n",
    "try:\n",
    "    df_principal = pd.read_parquet(principal_parquet)\n",
    "except Exception:\n",
    "    # Se o carregamento falhar, assumimos que o usu√°rio ajustar√° o caminho.\n",
    "    # Para o prop√≥sito da resposta, o c√≥digo de visualiza√ß√£o √© fornecido.\n",
    "    pass\n",
    "\n",
    "# Configura√ß√£o de estilo visual\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# --- V1: Distribui√ß√£o da Nota M√©dia IMDb (Vari√°vel Alvo) ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_principal['imdb_rating_concatenada'].dropna(), kde=True, bins=30)\n",
    "plt.title('V1: Distribui√ß√£o da Nota M√©dia IMDb', fontsize=15)\n",
    "plt.xlabel('Nota IMDb')\n",
    "plt.ylabel('Frequ√™ncia')\n",
    "plt.show()\n",
    "\n",
    "# --- V2: Contagem de T√≠tulos Lan√ßados por D√©cada (Vari√°vel Temporal) ---\n",
    "# Filtrando anos razo√°veis (a partir de 1950)\n",
    "df_principal['release_decade'] = (df_principal['release_year'] // 10) * 10\n",
    "plt.figure(figsize=(12, 5))\n",
    "df_principal[df_principal['release_decade'] > 1950]['release_decade'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('V2: Contagem de T√≠tulos Lan√ßados por D√©cada', fontsize=15)\n",
    "plt.xlabel('D√©cada de Lan√ßamento')\n",
    "plt.ylabel('N√∫mero de T√≠tulos')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# --- V3: Distribui√ß√£o de T√≠tulos por Servi√ßo de Streaming (Vari√°vel Categ√≥rica) ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(y='streaming', data=df_principal, order=df_principal['streaming'].value_counts().index)\n",
    "plt.title('V3: Distribui√ß√£o de T√≠tulos por Servi√ßo de Streaming', fontsize=15)\n",
    "plt.xlabel('N√∫mero de T√≠tulos')\n",
    "plt.ylabel('Servi√ßo de Streaming')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eedeea9",
   "metadata": {},
   "source": [
    "### An√°lise Bivariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce47ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = '../data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "\n",
    "# 1. Carrega o DataFrame Principal\n",
    "try:\n",
    "    df_principal = pd.read_parquet(principal_parquet)\n",
    "except Exception as e:\n",
    "    print(f\"ERRO ao carregar o arquivo Parquet: {e}\")\n",
    "    print(\"Certifique-se de que o arquivo 'principal_tidy.parquet' foi gerado corretamente na etapa Tidy.\")\n",
    "    exit()\n",
    "\n",
    "# Remove Nulos na vari√°vel-alvo para an√°lises\n",
    "df_bivariada = df_principal.dropna(subset=['imdb_rating_concatenada']).copy()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# I. Rela√ß√£o entre SERVI√áO DE STREAMING e NOTA IMDb\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "print(\"### I. Streaming vs. IMDb Rating ###\")\n",
    "streaming_analise = df_bivariada.groupby('streaming')['imdb_rating_concatenada'].agg(\n",
    "    count='count',\n",
    "    media='mean',\n",
    "    mediana='median',\n",
    "    desvio_padrao='std',\n",
    "    min_rating='min',\n",
    "    max_rating='max'\n",
    ").sort_values(by='media', ascending=False).round(2)\n",
    "\n",
    "print(\"\\n[M√©tricas do IMDb Rating por Servi√ßo de Streaming]\")\n",
    "print(streaming_analise.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# II. Rela√ß√£o entre TIPO DE T√çTULO (Movie/TV Show) e NOTA IMDb\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n### II. Tipo de T√≠tulo vs. IMDb Rating ###\")\n",
    "type_analise = df_bivariada.groupby('type')['imdb_rating_concatenada'].agg(\n",
    "    count='count',\n",
    "    media='mean',\n",
    "    mediana='median',\n",
    "    desvio_padrao='std',\n",
    ").sort_values(by='media', ascending=False).round(2)\n",
    "\n",
    "print(\"\\n[M√©tricas do IMDb Rating por Tipo de T√≠tulo]\")\n",
    "print(type_analise.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# III. Rela√ß√£o entre TOP G√äNEROS e NOTA IMDb\n",
    "# (Usando as colunas Dummy para comparar a nota m√©dia dos t√≠tulos que possuem o g√™nero)\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n### III. Top G√™neros vs. IMDb Rating ###\")\n",
    "\n",
    "# Seleciona as colunas dummy de G√™nero\n",
    "genre_cols = df_bivariada.filter(like='Genre_').columns\n",
    "\n",
    "# Cria uma lista para armazenar os resultados\n",
    "genero_ratings = []\n",
    "\n",
    "# Analisa o rating m√©dio para os t√≠tulos que cont√™m cada g√™nero (onde Genre_X == 1)\n",
    "for col in genre_cols:\n",
    "    media = df_bivariada[df_bivariada[col] == 1]['imdb_rating_concatenada'].mean()\n",
    "    contagem = df_bivariada[df_bivariada[col] == 1].shape[0]\n",
    "    \n",
    "    if contagem >= 50: # Filtra g√™neros com poucas observa√ß√µes\n",
    "        genero_ratings.append({\n",
    "            'G√™nero': col.replace('Genre_', ''),\n",
    "            'M√©dia Rating': round(media, 2),\n",
    "            'Contagem': contagem\n",
    "        })\n",
    "\n",
    "df_genero_ratings = pd.DataFrame(genero_ratings).sort_values(by='M√©dia Rating', ascending=False)\n",
    "\n",
    "print(\"\\n[Top G√™neros por M√©dia de IMDb Rating (Contagem m√≠nima de 50)]\")\n",
    "print(df_genero_ratings.head(10).to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ff0de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = '../data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "\n",
    "# Carrega o DataFrame principal\n",
    "try:\n",
    "    df_principal = pd.read_parquet(principal_parquet)\n",
    "except Exception:\n",
    "    # Caso o carregamento falhe no ambiente, o usu√°rio ajustar√° o caminho\n",
    "    pass\n",
    "\n",
    "# DataFrame para an√°lise bivariada (sem nulos no alvo)\n",
    "df_bivariada = df_principal.dropna(subset=['imdb_rating_concatenada']).copy()\n",
    "\n",
    "# Configura√ß√£o de estilo visual\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# --- V4: Distribui√ß√£o da Nota IMDb por Servi√ßo de Streaming (Box Plot) ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='streaming', y='imdb_rating_concatenada', data=df_bivariada, palette=\"Set2\")\n",
    "plt.title('V4: Distribui√ß√£o da Nota IMDb por Servi√ßo de Streaming', fontsize=15)\n",
    "plt.xlabel('Servi√ßo de Streaming')\n",
    "plt.ylabel('Nota IMDb')\n",
    "plt.show()\n",
    "\n",
    "# --- V5: Distribui√ß√£o da Nota IMDb por Tipo de T√≠tulo (Box Plot) ---\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='type', y='imdb_rating_concatenada', data=df_bivariada, palette=\"viridis\")\n",
    "plt.title('V5: Distribui√ß√£o da Nota IMDb por Tipo de T√≠tulo', fontsize=15)\n",
    "plt.xlabel('Tipo de T√≠tulo')\n",
    "plt.ylabel('Nota IMDb')\n",
    "plt.show()\n",
    "\n",
    "# --- V6: Top 5 G√™neros vs. M√©dia de Nota IMDb (Bar Plot) ---\n",
    "\n",
    "# 1. Identifica os Top 5 G√™neros por Volume\n",
    "genre_cols = df_bivariada.filter(like='Genre_').columns\n",
    "top_genres_by_volume = df_bivariada[genre_cols].sum().sort_values(ascending=False).head(5).index.tolist()\n",
    "\n",
    "# 2. Calcula a M√©dia de Rating para cada Top G√™nero\n",
    "genre_mean_ratings = []\n",
    "for col in top_genres_by_volume:\n",
    "    mean_rating = df_bivariada[df_bivariada[col] == 1]['imdb_rating_concatenada'].mean()\n",
    "    genre_mean_ratings.append({\n",
    "        'G√™nero': col.replace('Genre_', ''),\n",
    "        'M√©dia Rating': mean_rating\n",
    "    })\n",
    "\n",
    "df_genre_ratings = pd.DataFrame(genre_mean_ratings).sort_values(by='M√©dia Rating', ascending=False)\n",
    "\n",
    "# 3. Plota o resultado\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='M√©dia Rating', y='G√™nero', data=df_genre_ratings, palette=\"coolwarm\")\n",
    "plt.title('V6: M√©dia de Nota IMDb pelos Top 5 G√™neros', fontsize=15)\n",
    "plt.xlabel('M√©dia de Nota IMDb')\n",
    "plt.ylabel('G√™nero')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae794bbe",
   "metadata": {},
   "source": [
    "### An√°lise Multivariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0895a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = '../data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "\n",
    "# 1. Carrega o DataFrame Principal\n",
    "try:\n",
    "    df_principal = pd.read_parquet(principal_parquet)\n",
    "except Exception as e:\n",
    "    print(f\"ERRO ao carregar o arquivo Parquet: {e}\")\n",
    "    print(\"Certifique-se de que o arquivo 'principal_tidy.parquet' foi gerado corretamente.\")\n",
    "    exit()\n",
    "\n",
    "# Remove Nulos na vari√°vel-alvo\n",
    "df_multi = df_principal.dropna(subset=['imdb_rating_concatenada']).copy()\n",
    "\n",
    "\n",
    "# 2. Seleciona as colunas para correla√ß√£o\n",
    "# Inclui a vari√°vel-alvo (IMDb Rating) e todas as colunas dummy de G√™nero/Pa√≠s\n",
    "correlation_cols = ['imdb_rating_concatenada']\n",
    "correlation_cols.extend(df_multi.filter(like='Genre_').columns.tolist())\n",
    "correlation_cols.extend(df_multi.filter(like='Country_').columns.tolist())\n",
    "\n",
    "df_corr = df_multi[correlation_cols]\n",
    "\n",
    "# 3. Calcula o Coeficiente de Correla√ß√£o de Pearson\n",
    "# A correla√ß√£o entre uma vari√°vel num√©rica e uma bin√°ria (0 ou 1) √© v√°lida.\n",
    "correlation_matrix = df_corr.corr()\n",
    "\n",
    "# 4. Extrai a correla√ß√£o da vari√°vel-alvo (imdb_rating_concatenada) com todas as outras\n",
    "imdb_correlations = correlation_matrix['imdb_rating_concatenada'].sort_values(ascending=False)\n",
    "\n",
    "# Remove a autocorrela√ß√£o (1.0)\n",
    "imdb_correlations = imdb_correlations.drop('imdb_rating_concatenada')\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 5. Exibe os Resultados (Top 10 Positivos e Negativos)\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "print(\"### Resultados da An√°lise Multivariada: Correla√ß√£o com IMDb Rating ###\")\n",
    "\n",
    "# Top 10 Correla√ß√µes Positivas (Features que mais aumentam o Rating)\n",
    "top_positive = imdb_correlations.head(10).reset_index()\n",
    "top_positive.columns = ['Feature', 'Correla√ß√£o']\n",
    "print(\"\\n[Top 10 Correla√ß√µes POSITIVAS (Maior Peso no Rating)]\")\n",
    "print(top_positive.to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "# Top 10 Correla√ß√µes Negativas (Features que mais diminuem o Rating)\n",
    "top_negative = imdb_correlations.tail(10).reset_index()\n",
    "top_negative.columns = ['Feature', 'Correla√ß√£o']\n",
    "print(\"\\n[Top 10 Correla√ß√µes NEGATIVAS (Menor Peso no Rating)]\")\n",
    "print(top_negative.to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4f859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = '../data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "\n",
    "# 1. Carrega o DataFrame principal e prepara para correla√ß√£o\n",
    "try:\n",
    "    df_principal = pd.read_parquet(principal_parquet)\n",
    "except Exception:\n",
    "    # Se o carregamento falhar, o usu√°rio ajustar√° o caminho.\n",
    "    pass\n",
    "\n",
    "df_multi = df_principal.dropna(subset=['imdb_rating_concatenada']).copy()\n",
    "\n",
    "# 2. Seleciona colunas e calcula a Correla√ß√£o de Pearson com o alvo\n",
    "correlation_cols = ['imdb_rating_concatenada']\n",
    "correlation_cols.extend(df_multi.filter(like='Genre_').columns.tolist())\n",
    "correlation_cols.extend(df_multi.filter(like='Country_').columns.tolist())\n",
    "df_corr = df_multi[correlation_cols]\n",
    "correlation_matrix = df_corr.corr()\n",
    "imdb_correlations = correlation_matrix['imdb_rating_concatenada'].drop('imdb_rating_concatenada').sort_values(ascending=False)\n",
    "\n",
    "# 3. Prepara dados para plotagem: Top 10 Positivos e Top 10 Negativos\n",
    "top_positive = imdb_correlations.head(10).reset_index()\n",
    "top_negative = imdb_correlations.tail(10).reset_index()\n",
    "df_top_corr = pd.concat([top_positive, top_negative])\n",
    "df_top_corr.columns = ['Feature', 'Correlation']\n",
    "\n",
    "# Limpa nomes das features para melhor visualiza√ß√£o\n",
    "df_top_corr['Feature'] = df_top_corr['Feature'].str.replace('Genre_', 'G√™nero: ').str.replace('Country_', 'Pa√≠s: ')\n",
    "df_top_corr = df_top_corr.sort_values(by='Correlation', ascending=False)\n",
    "\n",
    "# 4. Plotagem dos Top 20 features mais correlacionadas\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# CORRE√á√ÉO: Converte a Series de cores para uma LISTA de Python com .tolist()\n",
    "cores_personalizadas = df_top_corr['Correlation'].apply(lambda x: 'darkgreen' if x > 0 else 'darkred').tolist()\n",
    "\n",
    "sns.barplot(x='Correlation', y='Feature', data=df_top_corr, \n",
    "            palette=cores_personalizadas) # Usa a lista de cores corrigida\n",
    "\n",
    "plt.title('V7: Top 20 Correla√ß√µes (IMDb Rating vs. Pa√≠ses e G√™neros)', fontsize=16)\n",
    "plt.xlabel('Coeficiente de Correla√ß√£o de Pearson')\n",
    "plt.ylabel('Feature (G√™nero ou Pa√≠s)')\n",
    "plt.axvline(x=0, color='black', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b309d033",
   "metadata": {},
   "source": [
    "### Testes de Hip√≥tese\n",
    "‚Ä¢ H1: Filmes de terror costumam ter uma nota menor que a m√©dia\n",
    "\n",
    "‚Ä¢ H2: Filmes no Disney Plus chegam mais r√°pido ao streaming\n",
    "\n",
    "‚Ä¢ H3: Atores dedicados ao g√™nero de terror participam de menos produ√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b3fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o de Caminhos ---\n",
    "imdb_data_dir = '../data'\n",
    "principal_parquet = os.path.join(imdb_data_dir, 'principal_tidy.parquet')\n",
    "actors_parquet = os.path.join(imdb_data_dir, 'actors_tidy.parquet')\n",
    "\n",
    "# Conecta ao DuckDB\n",
    "con = duckdb.connect(database=':memory:', read_only=False)\n",
    "\n",
    "# Fun√ß√£o para executar SQL, retornar DataFrame e imprimir o resultado\n",
    "def run_and_get_df(query_title, sql_query):\n",
    "    print(f\"\\n--- Resultados do Teste: {query_title} ---\")\n",
    "    try:\n",
    "        result = con.execute(sql_query).fetchdf()\n",
    "        print(result.to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO: Falha ao executar a pesquisa SQL. Motivo: {e}\")\n",
    "        print(\"Verifique se os arquivos Parquet foram gerados e o caminho est√° correto.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# H1: Filmes de terror costumam ter uma nota menor que a m√©dia\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_h1 = f\"\"\"\n",
    "SELECT \n",
    "    ROUND(AVG(imdb_rating_concatenada), 2) AS media_geral_imdb,\n",
    "    ROUND(AVG(CASE WHEN \"Genre_Horror\" = 1 THEN imdb_rating_concatenada ELSE NULL END), 2) AS media_horror_imdb\n",
    "FROM '{principal_parquet}'\n",
    "WHERE type = 'Movie';\n",
    "\"\"\"\n",
    "df_h1_raw = run_and_get_df(\"H1: Nota de Filmes de Terror vs. M√©dia Geral\", query_h1)\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# H2: Filmes no Disney Plus chegam mais r√°pido ao streaming\n",
    "# (Medido pela diferen√ßa de anos entre Lan√ßamento e Adi√ß√£o ao Streaming)\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_h2 = f\"\"\"\n",
    "WITH Time_to_Stream AS (\n",
    "    SELECT\n",
    "        streaming,\n",
    "        -- Extrai o ano do campo date_added e subtrai do release_year\n",
    "        (CAST(SUBSTR(date_added, 1, 4) AS INTEGER) - release_year) AS time_to_stream_years\n",
    "    FROM '{principal_parquet}'\n",
    "    WHERE date_added IS NOT NULL AND release_year IS NOT NULL AND type = 'Movie'\n",
    ")\n",
    "SELECT\n",
    "    streaming,\n",
    "    ROUND(AVG(time_to_stream_years), 2) AS media_tempo_adicao_anos\n",
    "FROM Time_to_Stream\n",
    "WHERE streaming IN ('Disney+', 'Netflix', 'Prime Video')\n",
    "GROUP BY streaming\n",
    "ORDER BY media_tempo_adicao_anos ASC;\n",
    "\"\"\"\n",
    "df_h2 = run_and_get_df(\"H2: Tempo M√©dio de Adi√ß√£o ao Streaming (Filmes)\", query_h2)\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# H3: Atores dedicados ao g√™nero de terror participam de menos produ√ß√µes \n",
    "# (M√©dia de Participa√ß√£o de Atores (Terror vs. Todos os Outros))\n",
    "# -----------------------------------------------------------------------------------------\n",
    "query_h3_modified = f\"\"\"\n",
    "WITH Actor_Participation AS (\n",
    "    SELECT\n",
    "        t2.actor_name,\n",
    "        COUNT(t1.show_id) AS total_participations,\n",
    "        -- Indica se o ator participou de algum t√≠tulo de Terror (MAX > 0 implica em True)\n",
    "        MAX(t1.\"Genre_Horror\") AS is_horror_actor\n",
    "    FROM '{principal_parquet}' AS t1\n",
    "    JOIN '{actors_parquet}' AS t2 ON t1.show_id = t2.show_id\n",
    "    WHERE t2.actor_name != 'Unknown' AND t1.type = 'Movie' -- Focando apenas em Filmes\n",
    "    GROUP BY t2.actor_name\n",
    ")\n",
    "SELECT\n",
    "    'Atores de Terror' AS grupo_ator,\n",
    "    ROUND(AVG(total_participations), 2) AS media_titulos_por_ator\n",
    "FROM Actor_Participation\n",
    "WHERE is_horror_actor = 1\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'Outros Atores (N√£o Terror)' AS grupo_ator,\n",
    "    ROUND(AVG(total_participations), 2) AS media_titulos_por_ator\n",
    "FROM Actor_Participation\n",
    "WHERE is_horror_actor = 0 -- Todos os atores que n√£o t√™m participa√ß√£o no g√™nero Horror.\n",
    "\"\"\"\n",
    "df_h3 = run_and_get_df(\"H3: M√©dia de Participa√ß√£o de Atores (Terror vs. Outros)\", query_h3_modified)\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6efafc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_h1_raw is not None:\n",
    "    df_h1 = df_h1_raw.melt(var_name='Categoria', value_name='M√©dia Rating')\n",
    "    df_h1['Categoria'] = df_h1['Categoria'].replace({\n",
    "        'media_geral': 'M√©dia Geral (Filmes)',\n",
    "        'media_horror': 'M√©dia Terror (Filmes)'\n",
    "    })\n",
    "    # Visualiza√ß√£o V8\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.barplot(x='Categoria', y='M√©dia Rating', data=df_h1, palette=['grey', 'red'])\n",
    "    plt.title('V8: M√©dia de Nota IMDb: Filmes de Terror vs. Geral (H1)', fontsize=14)\n",
    "    plt.ylabel('M√©dia de Nota IMDb')\n",
    "    plt.ylim(df_h1['M√©dia Rating'].min() - 0.2, df_h1['M√©dia Rating'].max() + 0.1) # Ajuste din√¢mico\n",
    "    plt.show()\n",
    "\n",
    "if df_h2 is not None:\n",
    "    df_h2 = df_h2.sort_values('media_tempo_adicao_anos', ascending=True)\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    sns.barplot(x='streaming', y='media_tempo_adicao_anos', data=df_h2, palette=\"muted\")\n",
    "    plt.title('V9: Tempo M√©dio (Anos) entre Lan√ßamento e Adi√ß√£o (H2)', fontsize=14)\n",
    "    plt.xlabel('Servi√ßo de Streaming')\n",
    "    plt.ylabel('Tempo M√©dio de Espera (Anos)')\n",
    "    plt.show()\n",
    "\n",
    "if df_h3 is not None:\n",
    "    df_h3 = df_h3.sort_values('media_titulos_por_ator', ascending=False)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x='grupo_ator', y='media_titulos_por_ator', data=df_h3, palette=['darkred', 'grey'])\n",
    "    plt.title('V10: M√©dia de T√≠tulos Participados por Ator (H3)', fontsize=14)\n",
    "    plt.xlabel('Grupo de Atores')\n",
    "    plt.ylabel('M√©dia de T√≠tulos por Ator')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
